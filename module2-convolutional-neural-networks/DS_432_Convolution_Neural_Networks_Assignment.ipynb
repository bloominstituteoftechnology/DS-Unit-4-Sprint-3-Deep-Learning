{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DS_432_Convolution_Neural_Networks_Assignment.ipynb","provenance":[{"file_id":"https://github.com/ryanleeallred/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb","timestamp":1637632238626}],"collapsed_sections":[]},"kernelspec":{"display_name":"py37  (Python3)","language":"python","name":"py37"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"nteract":{"version":"0.23.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fc4yMj7mtCAZ"},"source":["\n","\n","## *Data Science Unit 4 Sprint 3 Assignment 2*\n","# Convolutional Neural Networks (CNNs)"]},{"cell_type":"markdown","metadata":{"id":"0lfZdD_cp1t5"},"source":["# Assignment\n","\n","- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n","- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n","- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n","\n","\n","You will apply three different CNN models to a binary image classification model using Keras. Classify images of mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n","\n","|Mountain (+)|Forest (-)|\n","|---|---|\n","|![](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data/train/mountain/art1131.jpg?raw=1)|![](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data/validation/forest/cdmc317.jpg?raw=1)|\n","\n","The problem is relatively difficult given that the sample is tiny: about 350 observations per class. However, this sample size might be something that you can expect when prototyping an image classification problem/solution at work Get accustomed to evaluating several different possible models."]},{"cell_type":"markdown","metadata":{"id":"1eawBP-otCAb"},"source":["# Pre-Trained Model\n","<a id=\"p1\"></a>\n","\n","Load a pre-trained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n","\n","```python\n","import numpy as np\n","\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model # This is the functional API\n","\n","resnet = ResNet50(weights='imagenet', include_top=False)\n","\n","```\n","\n","The `include_top` = False parameter in `ResNet50` will remove the fully connected layers from the ResNet model. The next step is to turn off the training of the ResNet layers. We want to use the learned parameters without updating them in future training passes. \n","\n","```python\n","for layer in resnet.layers:\n","    layer.trainable = False\n","```\n","\n","Using the Keras functional API, we will need to add additional full connected layers to our model. We removed the top layers, and we removed all previous fully connected layers. In other words, we kept only the feature processing portions of our network. The `GlobalAveragePooling2D` layer functions as a fancy flatten function by taking the average of each of the last convolutional layer outputs (two dimensional still). \n","\n","```python\n","x = resnet.output\n","x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(1, activation='sigmoid')(x)\n","model = Model(resnet.input, predictions)\n","```\n","\n","Your assignment is to apply the transfer learning above to classify images of mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n","\n","Steps to complete assignment: \n","1. Load in Image Data into NumPy arrays (`X`) \n","2. Create a `y` for the labels\n","3. Train your model with pre-trained layers from resnet\n","4. Report your model's accuracy"]},{"cell_type":"markdown","metadata":{"id":"xHBOEp77_LRY"},"source":["-----\n","\n","# GPU on Colab\n","\n","If you're working on Colab, you only have access to 2 processors, so your model training will be slow. However, if you turn on the GPU instance that you have access to, your model training will be faster!\n","\n","[**Instructions for turning on GPU on Colab**](https://colab.research.google.com/notebooks/gpu.ipynb)\n","\n","------"]},{"cell_type":"markdown","metadata":{"id":"CLdGdXCatCAb"},"source":["## Load in Data\n","\n","Loading data is surprisingly more complicated than it seems because you are working with directories of images instead of a single file. \n","\n","This boilerplate will help you download a zipped version of the directory of images. The directory is organized into **train** and **validation** directories which you can use inside an `ImageGenerator` class to stream batches of images through your model.  \n","\n"]},{"cell_type":"code","metadata":{"id":"PDYKkQNw_LRZ","executionInfo":{"status":"ok","timestamp":1639522456550,"user_tz":480,"elapsed":2922,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["from os import listdir\n","from os.path import isfile, join\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","import os\n","\n","import numpy as np\n","\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model # This is the functional API\n","\n","from tensorflow.keras import datasets\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwgASoWQ_LRa","executionInfo":{"status":"ok","timestamp":1639522458601,"user_tz":480,"elapsed":175,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["%matplotlib inline\n","%load_ext tensorboard"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZotV8NS_LRb"},"source":["# Clear any tensorboard logs from previous runs\n","!rm -rf ./logs/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"moRVuHUqtCAc"},"source":["### Download & Summarize the Data\n","\n","This step is completed for you. Just run the cells and review the results. "]},{"cell_type":"code","metadata":{"id":"AR66H8o9tCAc","executionInfo":{"status":"ok","timestamp":1639524053136,"user_tz":480,"elapsed":925,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# data url\n","_URL = 'https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data.zip?raw=true'\n","\n","# download data and save to `file_name`\n","file_name = './data.zip'\n","path_to_zip = tf.keras.utils.get_file(file_name, origin=_URL, extract=True,cache_dir='/content')\n","\n","\n","# get absolute path to location of the data that we just downloaded\n","PATH = os.path.join(os.path.dirname(path_to_zip), 'data')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ius8bOYa_LRc","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1639524056562,"user_tz":480,"elapsed":138,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"8771c462-27e6-46a3-8625-61bac5d93d8b"},"source":["# protip: go to your terminal and paste the output below and cd into it\n","# explore it a bit...we'll come back to this later - muahahaha!!!\n","PATH"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/datasets/./data'"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["%ls /content/datasets/./data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0n7rYSYOKU8k","executionInfo":{"status":"ok","timestamp":1639524073210,"user_tz":480,"elapsed":286,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"e0536676-5784-4783-fffb-15f51d566414"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalidation\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"MNFsIu_KtCAg","executionInfo":{"status":"ok","timestamp":1639522470157,"user_tz":480,"elapsed":124,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# create train data dir path\n","train_dir = os.path.join(PATH, 'train')\n","\n","# create validation data dir path\n","validation_dir = os.path.join(PATH, 'validation')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsI9BQLotCAj","executionInfo":{"status":"ok","timestamp":1639522472436,"user_tz":480,"elapsed":155,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# train directory with mountian data sub-dir \n","train_mountain_dir = os.path.join(train_dir, 'mountain') \n","\n","# train directory with forest data sub-dir \n","train_forest_dir = os.path.join(train_dir, 'forest')  \n","\n","# validation directory with mountain data sub-dir \n","validation_mountain_dir = os.path.join(validation_dir, 'mountain')  \n","\n","# validation directory with forest data sub-dir \n","validation_forest_dir = os.path.join(validation_dir, 'forest')  "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NUs1e5-XtCAl","executionInfo":{"status":"ok","timestamp":1639522475835,"user_tz":480,"elapsed":127,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}}},"source":["# get the number of samples in each of the sub-dir \n","num_mountain_tr = len(os.listdir(train_mountain_dir))\n","num_forest_tr = len(os.listdir(train_forest_dir))\n","\n","num_mountain_val = len(os.listdir(validation_mountain_dir))\n","num_forest_val = len(os.listdir(validation_forest_dir))\n","\n","# get the total number of samples for the train and validation sets\n","total_train = num_mountain_tr + num_forest_tr\n","total_val = num_mountain_val + num_forest_val"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmklbgSMtCAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639522478264,"user_tz":480,"elapsed":131,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"}},"outputId":"ca68bffc-8833-4b8a-dc9a-931c0c6191a7"},"source":["print('total training mountain images:', num_mountain_tr)\n","print('total training forest images:', num_forest_tr)\n","\n","print('total validation mountain images:', num_mountain_val)\n","print('total validation forest images:', num_forest_val)\n","print(\"--\")\n","print(\"Total training images:\", total_train)\n","print(\"Total validation images:\", total_val)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["total training mountain images: 254\n","total training forest images: 270\n","total validation mountain images: 125\n","total validation forest images: 62\n","--\n","Total training images: 524\n","Total validation images: 187\n"]}]},{"cell_type":"markdown","metadata":{"id":"0QBSj-OR_LRe"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"dQ4ag4ultCAq"},"source":["### Use Keras `ImageDataGenerator` to Process the Data\n","\n","This step is completed for you, but please review the code. The `ImageDataGenerator` class reads in batches of data from a directory and passes them to the model one batch at a time. Like large text files, this method is advantageous because it stifles the need to load many images into memory.\n","\n","At this point you should review the documentation for the [Keras ImageDataGenerator Class](https://keras.io/preprocessing/image/#imagedatagenerator-class). <br>\n","You'll expand its use in the next section."]},{"cell_type":"code","metadata":{"id":"67i9IW49tCAq"},"source":["batch_size = 16\n","epochs = 10 # feel free to change this value only after you've gone through the notebook once  \n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1wNKMo1tCAt"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# ImageDataGenerator can rescale data from within \n","max_pixel_val = 255.\n","rescale = 1./max_pixel_val\n","\n","# Generator for our training data\n","train_image_generator = ImageDataGenerator(rescale=rescale) \n","                                           \n","# Generator for our validation data                                           \n","validation_image_generator = ImageDataGenerator(rescale=rescale) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndsuM4L9tCAv"},"source":["# Takes the path to a directory and generates batches of augmented data\n","train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory=train_dir,\n","                                                           shuffle=True,\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary', \n","                                                           color_mode='rgb')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOUTWqD2_LRf"},"source":["# explore some of `train_data_gen` attributes to get a sense of what this object can do for you\n","# YOUR CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kxlk3optCAy"},"source":["# Takes the path to a directory & generates batches of augmented data\n","val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory=validation_dir,\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='binary', \n","                                                              color_mode='rgb')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uFUl9DQN_LRg"},"source":["# explore some of `val_data_gen` attributes to get a sense of what this object can do for you\n","# YOUR CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2l7ue6NutCA0"},"source":["_____\n","## Instantiate Model\n","\n","Here your job is to take the python code at the beginning of the notebook (in the markdown cell) and turn it into working code. \n","\n","Most of the code that you'll need to build a model is in that markdown cell, though you'll still need to compile the model.\n","\n","Some pseudo-code is provided as a guide. "]},{"cell_type":"code","metadata":{"deletable":false,"id":"mKNIYOEItCA0","nbgrader":{"cell_type":"code","checksum":"3ef6aebc8089f2297504b310c583cb98","grade":false,"grade_id":"cell-f5f8bf566ce32a9b","locked":false,"schema_version":3,"solution":true,"task":false}},"source":["# load in the pre-trained model\n","# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gyjAtLTkcQj4"},"source":["### \"Freeze\" all the pretrained resnet50 weights and biases \n","so they will *not* be updated by gradient descent and backpropagation during training. <br>\n","Your model will train only the additional dense layers the classification part that you add to it below. <br>This is the essence of **Transfer Learning**: adapting a pre-trained model to a new data set that is different from the data used to train the mode."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"16a5d78e4c810864427217d8846aa811","grade":false,"grade_id":"cell-c9ce632ff4dce6bc","locked":false,"schema_version":3,"solution":true,"task":false},"id":"C8BSyRjz_LRh"},"source":["# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"93c62210094db18dc989941d624caa9f","grade":false,"grade_id":"cell-9ab2a3f78406ccee","locked":false,"schema_version":3,"solution":true,"task":false},"id":"SXwptGVm_LRh"},"source":["# take the model output layer as a starting point\n","\n","# take a global average pool\n","\n","# add a trainable hidden layer with 1024 nodes \n","\n","# add a trainable output layer \n","\n","# put it all together using the Keras's Model api\n","\n","\n","# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"4fb9a9608c3d9bc53d7d570ae4e9eaf9","grade":false,"grade_id":"cell-2f47a473b5842014","locked":false,"schema_version":3,"solution":true,"task":false},"id":"YlMRjhkI_LRh"},"source":["# the only code that is missing is the compile method \n","\n","# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BVPBWYG7tCA2"},"source":["## Fit Model"]},{"cell_type":"code","metadata":{"id":"9NpArCzp_LRh"},"source":["# include the callback into the fit method\n","# we'll launch tensorboard in the last section\n","logdir = os.path.join(\"logs\", \"resnet_model\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4XdvWA5tCA3"},"source":["history = model.fit(\n","    train_data_gen,\n","    steps_per_epoch=total_train // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=total_val // batch_size,\n","    workers=1, # num should be 1 or 2 processors less than the total number of process on your machine\n","    callbacks=[tensorboard_callback]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X0UuYU1o_LRi"},"source":["## Take Away\n","\n","The above task is an exercise in using a pre-trained model in the context of **Transfer Learning**. \n","\n","**Transfer Learning** happens when you take a model trained on a data set $A$ and apply it to the data set $B$. You may or may not choose to re-train the model.\n","\n","We loaded in a pre-trained model (meaning the weight values have been optimized in a previous fit) and updated the values of the weights by re-training them. Note that we didn't reset the model weights; we just continued their training on a different dataset, our data set. \n"]},{"cell_type":"markdown","metadata":{"id":"UPzsgS94tCA5"},"source":["-----\n","# Custom CNN Model\n","\n","In this step, write and train your convolutional neural network using Keras. You can use any architecture that suits you as long as it has at least one convolutional and one pooling layer at the beginning of the network - you can add more if you want. \n","\n","**Protip:** You'll be creating a 2nd instance of this same model in the next section. Instead of copying and pasting all this code, embed it in a `def create_model()` that returns a compiled model. \n","\n","Free to reference the custom CNN model that we built together in the guided project. "]},{"cell_type":"code","metadata":{"deletable":false,"id":"hnbJJie3tCA5","nbgrader":{"cell_type":"code","checksum":"4fe146a54f63df2e46fa8396e93b1532","grade":false,"grade_id":"cell-f3d186ae68873264","locked":false,"schema_version":3,"solution":true,"task":false}},"source":["def create_model():\n","    \"\"\"\n","    Since we'll be using this model again in the next section, it's useful to create a function \n","    that returns a compiled model.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tussXeGS_LRi"},"source":["# instantiate a model \n","model = create_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTpyAncr_LRi"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fx3aFuQI_LRi"},"source":["# include this callback in your fit method\n","# we'll launch tensorboard in the last section\n","logdir = os.path.join(\"logs\", \"baseline_model\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwM4GsaetCA_"},"source":["# Fit Model\n","epochs = 10\n","history = model.fit(\n","    train_data_gen,\n","    steps_per_epoch=total_train // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=total_val // batch_size,\n","    workers=10, # num should be 1 or 2 processors less than the total number of process on your machine \n","    callbacks=[tensorboard_callback]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FNTHjUddtCBB"},"source":["------\n","# Custom CNN Model with Image Augmentation\n","\n","To simulate an increase in an image sample, you can apply image manipulation techniques: cropping, rotation, stretching, etc. <br>\n","Luckily, Keras has some handy functions for us to apply these techniques to our mountain and forest example. In addition, you should be able to modify our image generator for the problem. Check out these resources to help you get started: \n","\n","1. [**Keras ImageGenerator Class**](https://keras.io/preprocessing/image/#imagedatagenerator-class) documentation for the tool that we need to use to augment our images\n","2. [**Building a powerful image classifier with very little data**](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) This is essentially a tutorial on using the ImageGenerator class to create augmented images. You can essentially copy and paste the relevant code, though don't do that blindly! \n"," "]},{"cell_type":"markdown","metadata":{"id":"tE6HETY9_LRj"},"source":["### Use ImageDataGenerator to Create Augmented Data\n","\n","Use the parameters for ImageDataGenerator that will enable you to generate an augmented version of images that we already have. Here are some of the relevant parameters to help you get started. \n","\n","- rescale\n","- shear_range\n","- zoom_range\n","- horizontal_flip\n","\n","### Only Create Augmented Images for the Training Data\n","\n","We want to be able to make a comparison with the same CNN model (or models) from above. \n","\n","To do that, we will augment the training data but not the validation data. Then we'll compare the accuracy and loss on the validation set. \n","\n","That way, we are comparing the performance of the same model architecture on the same test set; the only difference will be the augmented training data.Therefore, we'll be in a position to determine if augmenting our training data helped improve our model performance. \n","\n","This is an example of a controlled experiment."]},{"cell_type":"code","metadata":{"id":"XKioBv3WtCBB"},"source":["batch_size = 16\n","\n","# ImageDataGenerator can rescale data from within \n","max_pixel_val = 255.\n","rescale = 1./max_pixel_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_c1LPMAhNju"},"source":["# YOUR CODE HERE\n","# create an ImageDataGenerator instance - save result to `train_datagen_aug`\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"d40af8e7b09b4fccca8aec84f908e8ff","grade":false,"grade_id":"cell-d458fa433ebcf555","locked":false,"schema_version":3,"solution":true,"task":false},"id":"j58t0ITa_LRk"},"source":["# call the .flow_from_directory() method - save result to `train_data_gen_aug`\n","# protip: be mindful of the parameters\n","\n","# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oh_nrYbJ_LRk"},"source":["### Augment a Single Image\n","\n","Now that you have instantiated the `ImageDataGenerator` object that created augmented images for the training set.  Let's visual those augmented images to get a sense of what augmented images look like! \n"]},{"cell_type":"code","metadata":{"id":"67w2VBka_LRk"},"source":["# filename of image that we will augment\n","# this is just one of 100's of training images to choose from\n","# feel free to explore the training data directories and choose another image\n","# this image was selected from the mountain images \n","img_to_aug = \"art1131.jpg\"\n","\n","# replace with YOUR home directory name \n","home_dir = \"alexanderbarriga\"\n","\n","# create absolute file path to image file\n","path_to_single_img = \"./datasets/data/train/mountain/{0}\".format(img_to_aug)\n","\n","path_to_single_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpPmR6bh_LRk"},"source":["# load in image from file and reshape\n","img = load_img(path_to_single_img)  \n","x = img_to_array(img) \n","x = x.reshape((1,) + x.shape)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9BfEv1qd_LRk"},"source":["Create a temporary directory to store the augmented images that we will create to visualize. "]},{"cell_type":"code","metadata":{"id":"rrSovtiM_LRk"},"source":["# this is a terminal command that we are running in the notebook by including a `!` \n","# feel free to delete this temp dir after visualizing the aug images below\n","# you only need to create this dir once\n","!mkdir preview_img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xT0U8L4O_LRk"},"source":["Use the training data generator we just created to create 20 augmented images of the same original image."]},{"cell_type":"code","metadata":{"id":"wHAfcJGz_LRk"},"source":["# the .flow() command below generates batches of randomly transformed images\n","# and saves the results to the `preview_img` directory\n","\n","# create 20 aug images\n","n_aug_imgs_to_create = 20\n","i = 0\n","for batch in train_datagen_aug.flow(x, \n","                                    batch_size=1,\n","                                    save_to_dir='preview_img', \n","                                    save_prefix='art', \n","                                    save_format='jpeg'):\n","    i += 1\n","    if i > n_aug_imgs_to_create:\n","        break  # otherwise the generator would loop indefinitely"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwPQrqsK_LRl"},"source":["# create list populated with augmented image filenames\n","file_names = [f for f in listdir(\"preview_img\") if isfile(join(\"preview_img\", f))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzxfeSCt_LRl"},"source":["# load and prep images into a list \n","aug_imgs = []\n","for filename in file_names:\n","\n","    img = load_img(\"preview_img/{}\".format(filename)) \n","    a_img = img_to_array(img)  \n","    a_img = a_img.reshape((1,) + x.shape) \n","    aug_imgs.append(a_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mQ9IjNQ_LRl"},"source":["# notice that we are playing with a rank 5 tensor \n","# we can ignore the first two numbers\n","a_img.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7C5s4r0_LRl"},"source":["# the last 3 numbers have the actual image data\n","# (num 1, num 2, num 3) = (img height, img width, color channels)\n","a_img[0][0].shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wCT4NSnZ_LRl"},"source":["### Visualize Augmented Images\n","\n","Notice that the augmented images are just the original image with slight changes. For example, one image might be flipped to the y-axis or shifted along the x or y-axis, and the right-hand side might be clipped, the image might be scaled up or down, or some combination of changes. "]},{"cell_type":"code","metadata":{"id":"qK7U6cxc_LRl"},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20,20))\n","for i, a_img in enumerate(aug_imgs):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(a_img[0][0]/255.)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NeLpJ-0k_LRl"},"source":["Now the real question is, does any of this ultimately matter? For example, do these changes help our model's ability to learn and generalize better? Well, let's go ahead and run that experiment. \n","\n","-----"]},{"cell_type":"markdown","metadata":{"id":"5n5W2rtg_LRl"},"source":["## Re-train Your Custom CNN Model Using the Augmented Dataset\n","\n","We have created a data generator that creates augmented versions of the training images (and not the validation images). Thus, we can create a new instance of our custom CNN model with the same architecture, same parameters such as batch size and epochs, and see if augmented data helps. "]},{"cell_type":"code","metadata":{"id":"XrWRmzT-_LRm"},"source":["aug_model = create_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oG2LHML_LRm"},"source":["aug_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_mI7_w5_LRm"},"source":["logdir = os.path.join(\"logs\", \"aug_model\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pWNYL0j_LRm"},"source":["# Fit Model\n","\n","epochs = 10\n","\n","history = aug_model.fit(\n","    train_data_gen_aug,\n","    steps_per_epoch=total_train // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=total_val // batch_size,\n","    workers=10, # num should be 1 or 2 processors less than the total number of process on your machine \n","    callbacks=[tensorboard_callback]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H9wkCHW9_LRm"},"source":["-----\n","\n","# Compare Model Results"]},{"cell_type":"code","metadata":{"id":"FDeoXYRL_LRm"},"source":["%tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXUjtO2Y_LRm"},"source":["------\n","\n","### Time for Questions \n","\n","Take a look at the `epoch_accuracy` plot and answer the following questions. \n","\n","Optionally move the `smoothing` slider all the way to zero to view the raw scores. \n","\n","By the way, your results may look different than your classmates depending on how you choose to build your custom CNN model. \n","\n","\n","**Question 1:** Which of the three models performed the best? "]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"c582761ccc143c5d248d27ce49160bb8","grade":true,"grade_id":"cell-0e8a26fd93ff75d1","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"nIdpawh5_LRm"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"lJ_MqWk9_LRn"},"source":["**Question 2:** Did augmenting the training data help our custom CNN model improve its score? If so, why, if not, why not?"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"36700b3583a95d15b36e934bf8e61b02","grade":true,"grade_id":"cell-05178550630857e1","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"2zGjjIKI_LRn"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"A5MtFuoC_LRn"},"source":["**Question 3:** Could one or more of the three models benefit from training on more than ten epochs? If so, why, if not, why not?"]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"5739b5ef24367658384ddbb226ab6756","grade":true,"grade_id":"cell-ce4cf1e6eb96f202","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"ShzvLy0r_LRn"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"qC-p-XRL_LRn"},"source":["**Question 4:** If you didn't use regularization for your custom CNN, do you think the baseline model and the aug model could improve their scores if regularization was used? If so, why, if not, why not?\n","\n","Consider reviewing your Sprint 2 Module Assignment 2 experimental results on regularization. "]},{"cell_type":"markdown","metadata":{"deletable":false,"nbgrader":{"cell_type":"markdown","checksum":"963bdf6b8a29e4d8166bef574ebe66d9","grade":true,"grade_id":"cell-9d8c200f58160233","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"UyMb2ldO_LRn"},"source":["YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"cizjQvHZ_LRn"},"source":["-----"]},{"cell_type":"markdown","metadata":{"id":"uT3UV3gap9H6"},"source":["# Resources and Stretch Goals\n","\n","Stretch goals\n","- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g., download images of parties, recognize all that contain balloons)\n","- Check out [other available pre-trained networks](https://tfhub.dev), try some, and compare\n","- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g., [Visual Genome](https://visualgenome.org/)) on the topic\n","- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n","- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed into your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n","\n","Resources\n","- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n","- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution-based object detection system, focused on inference speed (for applications too e.g., self-driving vehicles)\n","- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n","- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n","- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"]}]}