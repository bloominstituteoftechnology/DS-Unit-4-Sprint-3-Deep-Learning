{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ASIN19 - LS_DS_441_RNN_and_LSTM.ipynb","version":"0.3.2","provenance":[{"file_id":"1K8UQVbNsz7qILukLjXrLE_vF-Hit8lkc","timestamp":1564055162117},{"file_id":"1gkZFpDFVeRYb7R1sxDnw5hTuG0KZEgRg","timestamp":1563887539610}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_IizNKWLomoA"},"source":["<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n","<br></br>\n","<br></br>\n","\n","## *Data Science Unit 4 Sprint 4 Lesson 1*\n","\n","# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n","## _aka_ PREDICTING THE FUTURE!\n","\n","<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n","<br></br>\n","<br></br>\n","\n","> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n","\n","Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n","\n","A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n","\n","A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5_m0hJ4uCzHz"},"source":["## Time series with plain old regression\n","\n","Recurrences are fancy, and we'll get to those later - let's start with something simple. Regression can handle time series just fine if you just set them up correctly - let's try some made-up stock data. And to make it, let's use a few list comprehensions!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GkJUFfsgnqr_","colab":{}},"source":["import numpy as np\n","from random import random\n","days = np.array((range(28)))\n","stock_quotes = np.array([random() + day * random() for day in days])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y-ORgKGNBOcb","outputId":"b571f5c2-9e8b-4a50-872b-3c7611bc1b3b","executionInfo":{"status":"ok","timestamp":1563889164688,"user_tz":-60,"elapsed":334,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["stock_quotes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.62553482,  0.93722681,  1.64369778,  0.80933758,  2.61091575,\n","        2.81434341,  3.45197994,  4.66468418,  5.76615321,  2.16209137,\n","        9.29462991,  6.82454487, 10.68132482,  8.97813041,  8.65256138,\n","        7.62120527,  4.93780509,  5.62113869,  7.43521291, 18.00793116,\n","        8.8532704 ,  9.5836336 , 18.31386604,  4.69840129,  4.85972077,\n","       19.63411737, 17.97786292, 26.5107536 ])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X3lR2wGvBx3a"},"source":["Let's take a look with a scatter plot:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pVUTC2tmBSIq","outputId":"e8582312-bee1-4848-ab8a-e642667d3eee","executionInfo":{"status":"ok","timestamp":1563889167001,"user_tz":-60,"elapsed":920,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["from matplotlib.pyplot import scatter\n","scatter(days, stock_quotes);"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSASBDgCJINABIBEEOgAk4v8BdKamCygrA+EAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hgD4q-T_B0jd"},"source":["Looks pretty linear, let's try a simple OLS regression.\n","\n","First, these need to be NumPy arrays:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A3Q0MrnUBXAl","colab":{}},"source":["days = days.reshape(-1, 1)  # X needs to be column vectors"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eE0VFEXo4oaD","colab_type":"code","outputId":"c91334ec-f6a4-4207-9905-264aefc83aa6","executionInfo":{"status":"ok","timestamp":1563889170178,"user_tz":-60,"elapsed":800,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["days"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0],\n","       [ 1],\n","       [ 2],\n","       [ 3],\n","       [ 4],\n","       [ 5],\n","       [ 6],\n","       [ 7],\n","       [ 8],\n","       [ 9],\n","       [10],\n","       [11],\n","       [12],\n","       [13],\n","       [14],\n","       [15],\n","       [16],\n","       [17],\n","       [18],\n","       [19],\n","       [20],\n","       [21],\n","       [22],\n","       [23],\n","       [24],\n","       [25],\n","       [26],\n","       [27]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vqr0SHOnB5yR"},"source":["Now let's use good old `scikit-learn` and linear regression:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PqyHxgFvBYl5","outputId":"b0d9179d-bc1f-48c5-e1cf-7abbf2d7ba83","executionInfo":{"status":"ok","timestamp":1563889172180,"user_tz":-60,"elapsed":1192,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.linear_model import LinearRegression\n","ols_stocks = LinearRegression()\n","ols_stocks.fit(days, stock_quotes)\n","ols_stocks.score(days, stock_quotes)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5773497409992916"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KlU0mr-KB_Yk"},"source":["That seems to work pretty well, but real stocks don't work like this.\n","\n","Let's make *slightly* more realistic data that depends on more than just time:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-FV1Emb2BuLz","colab":{}},"source":["# Not everything is best as a comprehension\n","stock_data = np.empty([len(days), 4])\n","for day in days:\n","  asset = random()\n","  liability = random()\n","  quote = random() + ((day * random()) + (20 * asset) - (15 * liability))\n","  quote = max(quote, 0.01)  # Want positive quotes\n","  stock_data[day] = np.array([quote, day, asset, liability])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6Qe2zzN1CESe","outputId":"f5b08824-5f4c-49b7-9c2e-4aa091e81523","executionInfo":{"status":"ok","timestamp":1563889175229,"user_tz":-60,"elapsed":778,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["stock_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.27901992e+00, 0.00000000e+00, 1.36219905e-01, 1.20340573e-01],\n","       [1.81960153e+01, 1.00000000e+00, 9.47727309e-01, 1.12836964e-01],\n","       [4.16971069e+00, 2.00000000e+00, 8.03045750e-01, 9.31787665e-01],\n","       [1.96323933e+00, 3.00000000e+00, 6.17473008e-02, 1.37078734e-01],\n","       [9.71837947e+00, 4.00000000e+00, 8.77820747e-01, 7.77277856e-01],\n","       [1.36428564e+01, 5.00000000e+00, 5.70434280e-01, 2.02693739e-01],\n","       [1.13448268e+01, 6.00000000e+00, 7.26423180e-01, 3.86247075e-01],\n","       [2.25251439e+00, 7.00000000e+00, 1.64093964e-01, 3.17471565e-01],\n","       [1.00000000e-02, 8.00000000e+00, 3.57728094e-01, 9.73617350e-01],\n","       [1.09649515e+01, 9.00000000e+00, 5.56121840e-01, 3.80064196e-01],\n","       [1.71082160e+01, 1.00000000e+01, 8.13392273e-01, 6.16098156e-01],\n","       [6.81104524e+00, 1.10000000e+01, 6.24809499e-01, 8.13428895e-01],\n","       [2.29426696e+01, 1.20000000e+01, 9.80309431e-01, 4.85692099e-02],\n","       [3.82851289e+00, 1.30000000e+01, 3.10462706e-01, 6.05165031e-01],\n","       [1.00000000e-02, 1.40000000e+01, 4.67538188e-01, 9.92088596e-01],\n","       [9.71677265e+00, 1.50000000e+01, 4.67005478e-01, 5.09239954e-01],\n","       [2.51009638e+01, 1.60000000e+01, 8.17282631e-01, 4.57661165e-01],\n","       [1.00000000e-02, 1.70000000e+01, 6.83794672e-02, 3.17008319e-01],\n","       [1.22058816e+01, 1.80000000e+01, 5.10721593e-02, 1.27499542e-01],\n","       [1.43302772e+01, 1.90000000e+01, 8.63091135e-01, 9.45763909e-01],\n","       [2.20404722e+01, 2.00000000e+01, 9.09267289e-01, 9.36024439e-01],\n","       [2.16962070e+01, 2.10000000e+01, 6.87924263e-01, 5.85049650e-01],\n","       [1.11506360e+01, 2.20000000e+01, 4.81173606e-01, 9.77974415e-01],\n","       [1.28216245e+01, 2.30000000e+01, 7.98036749e-01, 3.46216721e-01],\n","       [1.52499234e+01, 2.40000000e+01, 6.66960045e-01, 3.71065912e-01],\n","       [8.40334515e+00, 2.50000000e+01, 3.38738238e-01, 4.21685303e-01],\n","       [3.20164959e+01, 2.60000000e+01, 7.83674835e-01, 4.23363914e-01],\n","       [2.21728051e+01, 2.70000000e+01, 9.33861268e-01, 3.90277362e-01]])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BzYy4Pb2CLCh"},"source":["Let's look again:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qdBcScz4CIXr","outputId":"2afc63a8-a5a3-41e0-edcb-cef6f7b02a25","executionInfo":{"status":"ok","timestamp":1563889176994,"user_tz":-60,"elapsed":589,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["stock_quotes = stock_data[:,0]\n","scatter(days, stock_quotes);"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQAyQaADQCb+HwBy5zN59zgVAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SBXb7dieCO5h"},"source":["How does our old model do?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7gAxCgy1COnX","outputId":"8e35d8c3-94da-4605-c11d-2df4e46fd3c9","executionInfo":{"status":"ok","timestamp":1563889179088,"user_tz":-60,"elapsed":856,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["days = np.array(days).reshape(-1, 1)\n","ols_stocks.fit(days, stock_quotes)\n","ols_stocks.score(days, stock_quotes)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.22512025717125905"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3E94vTFUCax_"},"source":["Not bad, but can we do better?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mCR5GImZCbGz","outputId":"49d2ae28-5990-457e-e770-ce187765b9ba","executionInfo":{"status":"ok","timestamp":1563889181070,"user_tz":-60,"elapsed":850,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ols_stocks.fit(stock_data[:,1:], stock_quotes)\n","ols_stocks.score(stock_data[:,1:], stock_quotes)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7744213949396949"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1Qk-jlBCCiKB"},"source":["Yep - unsurprisingly, the other covariates (assets and liabilities) have info.\n","\n","But, they do worse without the day data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dDcZl7I5Cf5D","outputId":"7183b3f0-fb1c-440b-f602-071a86ba2d9b","executionInfo":{"status":"ok","timestamp":1563889183174,"user_tz":-60,"elapsed":1024,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ols_stocks.fit(stock_data[:,2:], stock_quotes)\n","ols_stocks.score(stock_data[:,2:], stock_quotes)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.608949121226243"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pnLXlrK8ENjb"},"source":["## Time series jargon\n","\n","There's a lot of semi-standard language and tricks to talk about this sort of data. [NIST](https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm) has an excellent guidebook, but here are some highlights:"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yWUyhnTbcq55"},"source":["### Moving average\n","\n","Moving average aka rolling average aka running average.\n","\n","Convert a series of data to a series of averages of continguous subsets:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"47bHhBSCcvw-","outputId":"e886790b-951e-4532-87b8-665bc103578c","executionInfo":{"status":"ok","timestamp":1563889185489,"user_tz":-60,"elapsed":858,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["stock_quotes_rolling = [sum(stock_quotes[i:i+3]) / 3\n","                        for i in range(len(stock_quotes - 2))]\n","stock_quotes_rolling"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[7.881581953417857,\n"," 8.109655088073506,\n"," 5.2837764930641535,\n"," 8.441491746839501,\n"," 11.568687581984223,\n"," 9.080065891550024,\n"," 4.535780409073407,\n"," 4.409155290162668,\n"," 9.361055810090145,\n"," 11.628070889247054,\n"," 15.620643596214038,\n"," 11.194075907764395,\n"," 8.927060828607488,\n"," 4.518428511744975,\n"," 11.609245498301838,\n"," 11.609245498301838,\n"," 12.438948472401774,\n"," 8.848719598831202,\n"," 16.1922103293081,\n"," 19.35565214815637,\n"," 18.29577173250315,\n"," 15.222822495137436,\n"," 13.074061275287727,\n"," 12.15829766545131,\n"," 18.5565881230186,\n"," 20.864215352792417,\n"," 18.063100302454938,\n"," 7.3909350184431375]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"36XvbGhoc186"},"source":["Pandas has nice series related functions:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nTNatxtycys_","outputId":"d6c395e6-0988-4e0b-913f-5aa4facf6cd7","executionInfo":{"status":"ok","timestamp":1563889187735,"user_tz":-60,"elapsed":1061,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":917}},"source":["import pandas as pd\n","df = pd.DataFrame(stock_quotes)\n","df.rolling(3).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.881582</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8.109655</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.283776</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>8.441492</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11.568688</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9.080066</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4.535780</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4.409155</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>9.361056</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11.628071</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>15.620644</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>11.194076</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>8.927061</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4.518429</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>11.609245</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>11.609245</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>12.438948</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>8.848720</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>16.192210</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>19.355652</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>18.295772</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>15.222822</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>13.074061</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>12.158298</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>18.556588</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>20.864215</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            0\n","0         NaN\n","1         NaN\n","2    7.881582\n","3    8.109655\n","4    5.283776\n","5    8.441492\n","6   11.568688\n","7    9.080066\n","8    4.535780\n","9    4.409155\n","10   9.361056\n","11  11.628071\n","12  15.620644\n","13  11.194076\n","14   8.927061\n","15   4.518429\n","16  11.609245\n","17  11.609245\n","18  12.438948\n","19   8.848720\n","20  16.192210\n","21  19.355652\n","22  18.295772\n","23  15.222822\n","24  13.074061\n","25  12.158298\n","26  18.556588\n","27  20.864215"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"os-szg47dgwf"},"source":["### Forecasting\n","\n","Forecasting - at it's simplest, it just means \"predict the future\":"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D_qtt6irdj0x","outputId":"f3d71b4a-5273-4762-ecdb-c25879a94d58","executionInfo":{"status":"ok","timestamp":1563889189664,"user_tz":-60,"elapsed":904,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ols_stocks.fit(stock_data[:,1:], stock_quotes)\n","ols_stocks.predict([[29, 0.5, 0.5]])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([16.92319209])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fjnQY0trdnHp"},"source":["One way to predict if you just have the series data is to use the prior observation. This can be pretty good (if you had to pick one feature to model the temperature for tomorrow, the temperature today is a good choice)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bzC4DV9Hdupp","outputId":"534979ae-62ad-4469-e29c-e2a6da3bf8db","executionInfo":{"status":"ok","timestamp":1563889191994,"user_tz":-60,"elapsed":1111,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["temperature = np.array([30 + random() * day\n","                        for day in np.array(range(365)).reshape(-1, 1)])\n","temperature_next = temperature[1:].reshape(-1, 1)\n","temperature_ols = LinearRegression()\n","temperature_ols.fit(temperature[:-1], temperature_next)\n","temperature_ols.score(temperature[:-1], temperature_next)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2689464288030372"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RFdssXQbdxbE"},"source":["But you can often make it better by considering more than one prior observation."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pVfUqD2YdxxZ","outputId":"1b199259-6c11-4956-ac5e-b0c92acc5baf","executionInfo":{"status":"ok","timestamp":1563889193290,"user_tz":-60,"elapsed":349,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["temperature_next_next = temperature[2:].reshape(-1, 1)\n","temperature_two_past = np.concatenate([temperature[:-2], temperature_next[:-1]],\n","                                      axis=1)\n","temperature_ols.fit(temperature_two_past, temperature_next_next)\n","temperature_ols.score(temperature_two_past, temperature_next_next)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3210129312900477"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c9QltBdmd7TV"},"source":["### Exponential smoothing\n","\n","Exponential smoothing means using exponentially decreasing past weights to predict the future.\n","\n","You could roll your own, but let's use Pandas."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hvMNqunOeC_B","outputId":"e876a736-a075-46e6-bac6-37613e07f9c3","executionInfo":{"status":"ok","timestamp":1563889194819,"user_tz":-60,"elapsed":418,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["temperature_df = pd.DataFrame(temperature)\n","temperature_df.ewm(halflife=7).mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>30.350387</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30.302879</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>30.842250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.296326</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>31.792220</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>31.484005</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>31.295977</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>31.176837</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>32.218379</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>33.206270</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>33.096718</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>33.273866</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>33.366406</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>33.246005</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>33.321500</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>33.352035</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>34.883158</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>35.882388</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>35.315526</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>36.695662</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>36.177692</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>35.843162</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>37.065080</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>37.204962</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>38.811911</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>39.543154</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>39.658223</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>40.227509</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>41.842318</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>335</th>\n","      <td>195.571531</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>191.023298</td>\n","    </tr>\n","    <tr>\n","      <th>337</th>\n","      <td>206.736067</td>\n","    </tr>\n","    <tr>\n","      <th>338</th>\n","      <td>214.275822</td>\n","    </tr>\n","    <tr>\n","      <th>339</th>\n","      <td>224.471452</td>\n","    </tr>\n","    <tr>\n","      <th>340</th>\n","      <td>227.986260</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>217.274427</td>\n","    </tr>\n","    <tr>\n","      <th>342</th>\n","      <td>217.713526</td>\n","    </tr>\n","    <tr>\n","      <th>343</th>\n","      <td>201.621823</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>201.401745</td>\n","    </tr>\n","    <tr>\n","      <th>345</th>\n","      <td>217.700907</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>229.157580</td>\n","    </tr>\n","    <tr>\n","      <th>347</th>\n","      <td>235.998147</td>\n","    </tr>\n","    <tr>\n","      <th>348</th>\n","      <td>220.291259</td>\n","    </tr>\n","    <tr>\n","      <th>349</th>\n","      <td>230.304120</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>229.737954</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>237.853555</td>\n","    </tr>\n","    <tr>\n","      <th>352</th>\n","      <td>232.219369</td>\n","    </tr>\n","    <tr>\n","      <th>353</th>\n","      <td>219.052787</td>\n","    </tr>\n","    <tr>\n","      <th>354</th>\n","      <td>209.334327</td>\n","    </tr>\n","    <tr>\n","      <th>355</th>\n","      <td>214.956027</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>222.431804</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>208.704900</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>213.533394</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>197.521878</td>\n","    </tr>\n","    <tr>\n","      <th>360</th>\n","      <td>209.775042</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>200.757437</td>\n","    </tr>\n","    <tr>\n","      <th>362</th>\n","      <td>193.206945</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>188.900619</td>\n","    </tr>\n","    <tr>\n","      <th>364</th>\n","      <td>191.024815</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>365 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["              0\n","0     30.000000\n","1     30.350387\n","2     30.302879\n","3     30.842250\n","4     31.296326\n","5     31.792220\n","6     31.484005\n","7     31.295977\n","8     31.176837\n","9     32.218379\n","10    33.206270\n","11    33.096718\n","12    33.273866\n","13    33.366406\n","14    33.246005\n","15    33.321500\n","16    33.352035\n","17    34.883158\n","18    35.882388\n","19    35.315526\n","20    36.695662\n","21    36.177692\n","22    35.843162\n","23    37.065080\n","24    37.204962\n","25    38.811911\n","26    39.543154\n","27    39.658223\n","28    40.227509\n","29    41.842318\n","..          ...\n","335  195.571531\n","336  191.023298\n","337  206.736067\n","338  214.275822\n","339  224.471452\n","340  227.986260\n","341  217.274427\n","342  217.713526\n","343  201.621823\n","344  201.401745\n","345  217.700907\n","346  229.157580\n","347  235.998147\n","348  220.291259\n","349  230.304120\n","350  229.737954\n","351  237.853555\n","352  232.219369\n","353  219.052787\n","354  209.334327\n","355  214.956027\n","356  222.431804\n","357  208.704900\n","358  213.533394\n","359  197.521878\n","360  209.775042\n","361  200.757437\n","362  193.206945\n","363  188.900619\n","364  191.024815\n","\n","[365 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gBEjBZVbeH6R"},"source":["Halflife is among the parameters we can play with:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HjZgMwYkeODN","outputId":"7f7c99f5-a6e0-4637-a188-99e569d96ec9","executionInfo":{"status":"ok","timestamp":1563889197873,"user_tz":-60,"elapsed":849,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["sse_1 = ((temperature_df - temperature_df.ewm(halflife=7).mean())**2).sum()\n","sse_2 = ((temperature_df - temperature_df.ewm(halflife=3).mean())**2).sum()\n","print(sse_1)\n","print(sse_2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0    1.093939e+06\n","dtype: float64\n","0    882056.392083\n","dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s39bj4g9eQ9Z"},"source":["Note - the first error being higher doesn't mean it's necessarily *worse*. It's *smoother* as expected, and if that's what we care about - great!"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OcPMn8o4eYP1"},"source":["### Seasonality\n","\n","Seasonality - \"day of week\"-effects, and more. In a lot of real world data, certain time periods are systemically different, e.g. holidays for retailers, weekends for restaurants, seasons for weather.\n","\n","Let's try to make some seasonal data - a store that sells more later in a week:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h0qPMWCreheL","outputId":"1aae7422-a155-4c40-88df-198916aec97d","executionInfo":{"status":"ok","timestamp":1563889202225,"user_tz":-60,"elapsed":619,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["sales = np.array([random() + (day % 7) * random() for day in days])\n","scatter(days, sales)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7f704822c390>"]},"metadata":{"tags":[]},"execution_count":23},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nghsAgvk/1/3XbTkeJHQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LEADkcMzelxY"},"source":["How does linear regression do at fitting this?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EV5kt69GenV3","outputId":"97c611f5-6362-4530-99d7-ae0c3e53377e","executionInfo":{"status":"ok","timestamp":1563889207646,"user_tz":-60,"elapsed":836,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sales_ols = LinearRegression()\n","sales_ols.fit(days, sales)\n","sales_ols.score(days, sales)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.004012094103128305"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7shN1eBMep9Q"},"source":["That's not great - and the fix depends on the domain. Here, we know it'd be best to actually use \"day of week\" as a feature."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qo9eFlHIeqtA","outputId":"1b6b0b8d-ce4d-424a-b836-b2ddcf1b8970","executionInfo":{"status":"ok","timestamp":1563889209294,"user_tz":-60,"elapsed":500,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["day_of_week = days % 7\n","sales_ols.fit(day_of_week, sales)\n","sales_ols.score(day_of_week, sales)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4423149894959018"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9ooJIfIMex2G"},"source":["Note that it's also important to have representative data across whatever seasonal feature(s) you use - don't predict retailers based only on Christmas, as that won't generalize well."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"44QZgrPUe3-Y"},"source":["## Recurrent Neural Networks\n","\n","There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n","\n","$F_n = F_{n-1} + F_{n-2}$\n","\n","For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n","\n","![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n","\n","The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n","\n","Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n","\n","![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n","\n","There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n","\n","After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n","\n","So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n","\n","For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n","\n","- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n","- https://keras.io/layers/recurrent/#lstm\n","- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n","\n","Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eWrQllf8WEd-"},"source":["### RNN/LSTM Sentiment Classification with Keras"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ti23G0gRe3kr","outputId":"505e7d48-ce42-49ab-bc7f-f8304dd5960a","executionInfo":{"status":"error","timestamp":1563889214525,"user_tz":-60,"elapsed":2467,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"source":["'''\n","#Trains an LSTM model on the IMDB sentiment classification task.\n","The dataset is actually too small for LSTM to be of any advantage\n","compared to simpler, much faster methods such as TF-IDF + LogReg.\n","**Notes**\n","- RNNs are tricky. Choice of batch size is important,\n","choice of loss and optimizer is critical, etc.\n","Some configurations won't converge.\n","- LSTM loss decrease patterns during training can be quite different\n","from what you see with CNNs/MLPs/etc.\n","'''\n","from __future__ import print_function\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding\n","from keras.layers import LSTM\n","from keras.datasets import imdb\n","\n","max_features = 20000\n","# cut texts after this number of words (among top max_features most common words)\n","maxlen = 80\n","batch_size = 32\n","\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')\n","\n","print('Pad sequences (samples x time)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape:', x_train.shape)\n","print('x_test shape:', x_test.shape)\n","\n","print('Build model...')\n","model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# try using different optimizers and different optimizer configs\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print('Train...')\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=15,\n","          validation_data=(x_test, y_test))\n","score, acc = model.evaluate(x_test, y_test,\n","                            batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading data...\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-c26ac6abc1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train sequences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test sequences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     file_hash='599dadb1135973df5b59232a0e9a887c')\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    697\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7pETWPIe362y"},"source":["### RNN Text generation with NumPy\n","\n","What else can we do with RNN? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. We'll pull some news stories using [newspaper](https://github.com/codelucas/newspaper/)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fz1m55G5WSrQ"},"source":["#### Initialization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ahlHBeoZCaLX","outputId":"90da5a46-a63d-4a9c-f75f-be218463455a","executionInfo":{"status":"ok","timestamp":1563889276810,"user_tz":-60,"elapsed":4561,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":411}},"source":["!pip install newspaper3k"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: newspaper3k in /usr/local/lib/python3.6/dist-packages (0.2.8)\n","Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (1.0.3)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n","Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (5.2.1)\n","Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.3.0)\n","Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.35.1)\n","Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.2.1)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n","Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.3)\n","Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (0.0.4)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n","Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.5.3)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=3.3.0->newspaper3k) (0.46)\n","Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (41.0.1)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.12.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2019.6.16)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fTPlziljCiNJ","colab":{}},"source":["import newspaper"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bk9JF2zaCxoO","outputId":"047eea39-a4a9-4d50-b0a4-ca7d3de938de","executionInfo":{"status":"ok","timestamp":1563889292030,"user_tz":-60,"elapsed":11593,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["ap = newspaper.build('https://www.apnews.com')\n","len(ap.articles)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","E0723 13:41:27.881943 140120473368320 network.py:112] CRITICAL - [REQUEST FAILED] HTTPSConnectionPool(host='www.apnews.com', port=443): Read timed out. (read timeout=7)\n","E0723 13:41:27.892214 140119543248640 network.py:112] CRITICAL - [REQUEST FAILED] HTTPSConnectionPool(host='www.apnews.com', port=443): Read timed out. (read timeout=7)\n","E0723 13:41:28.140735 140119551641344 network.py:112] CRITICAL - [REQUEST FAILED] HTTPSConnectionPool(host='www.apnews.com', port=443): Read timed out. (read timeout=7)\n","E0723 13:41:28.793161 140119509677824 network.py:112] CRITICAL - [REQUEST FAILED] HTTPSConnectionPool(host='www.apnews.com', port=443): Read timed out. (read timeout=7)\n","E0723 13:41:30.189776 140119518070528 network.py:112] CRITICAL - [REQUEST FAILED] HTTPSConnectionPool(host='www.apnews.com', port=443): Read timed out. (read timeout=7)\n","W0723 13:41:30.192081 140121072080768 source.py:196] Deleting category https://www.apnews.com/TheresaMay from source https://www.apnews.com due to download error\n","W0723 13:41:30.194663 140121072080768 source.py:196] Deleting category https://www.apnews.com/Globaltrade from source https://www.apnews.com due to download error\n","W0723 13:41:30.201158 140121072080768 source.py:196] Deleting category https://www.apnews.com/Immigration from source https://www.apnews.com due to download error\n","W0723 13:41:30.210507 140121072080768 source.py:196] Deleting category https://www.apnews.com/SouthKorea from source https://www.apnews.com due to download error\n","W0723 13:41:30.214354 140121072080768 source.py:196] Deleting category https://www.apnews.com/BorisJohnson from source https://www.apnews.com due to download error\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Vc6JgAIJDF4E","outputId":"57a6e202-f17c-4166-a1ee-2519638d3851","executionInfo":{"status":"ok","timestamp":1563889302374,"user_tz":-60,"elapsed":1215,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["article_text = ''\n","\n","for article in ap.articles[:1]:\n","  try:\n","    article.download()\n","    article.parse()\n","    article_text += '\\n\\n' + article.text\n","  except:\n","    print('Failed: ' + article.url)\n","  \n","article_text = article_text.split('\\n\\n')[1]\n","print(article_text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Washington Capitals captain Alex Ovechkin will visit Beijing the week of Aug. 4 to serve as an â€œinternational ambassadorâ€ for the NHL as it seeks to grow hockey in China, the league announced Thursday.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rsMBBMcv_nRM","outputId":"567a2e57-224a-4855-8bc1-036457782e59","executionInfo":{"status":"ok","timestamp":1563889310786,"user_tz":-60,"elapsed":867,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Based on \"The Unreasonable Effectiveness of RNN\" implementation\n","import numpy as np\n","\n","chars = list(set(article_text)) # split and remove duplicate characters. convert to list.\n","\n","num_chars = len(chars) # the number of unique characters\n","txt_data_size = len(article_text)\n","\n","print(\"unique characters : \", num_chars)\n","print(\"txt_data_size : \", txt_data_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["unique characters :  39\n","txt_data_size :  201\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aQygqc_CAWRA","outputId":"3a7ef3e4-08c1-4dbf-e40c-f0a317944214","executionInfo":{"status":"ok","timestamp":1563889313822,"user_tz":-60,"elapsed":832,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["# one hot encode\n","char_to_int = dict((c, i) for i, c in enumerate(chars)) # \"enumerate\" retruns index and value. Convert it to dictionary\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\n","print(char_to_int)\n","print(\"----------------------------------------------------\")\n","print(int_to_char)\n","print(\"----------------------------------------------------\")\n","# integer encode input data\n","integer_encoded = [char_to_int[i] for i in article_text] # \"integer_encoded\" is a list which has a sequence converted from an original data to integers.\n","print(integer_encoded)\n","print(\"----------------------------------------------------\")\n","print(\"data length : \", len(integer_encoded))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'H': 0, 'n': 1, 'k': 2, 'â€': 3, 's': 4, 'v': 5, ' ': 6, '4': 7, 'L': 8, 'd': 9, 'a': 10, 'o': 11, 'w': 12, 'm': 13, 'l': 14, 'A': 15, 'C': 16, 'W': 17, 'e': 18, 'h': 19, 'u': 20, 'r': 21, 'B': 22, '.': 23, 'x': 24, 'b': 25, 'T': 26, 'f': 27, 'g': 28, 'N': 29, 't': 30, 'p': 31, 'y': 32, 'i': 33, ',': 34, 'â€œ': 35, 'c': 36, 'O': 37, 'j': 38}\n","----------------------------------------------------\n","{0: 'H', 1: 'n', 2: 'k', 3: 'â€', 4: 's', 5: 'v', 6: ' ', 7: '4', 8: 'L', 9: 'd', 10: 'a', 11: 'o', 12: 'w', 13: 'm', 14: 'l', 15: 'A', 16: 'C', 17: 'W', 18: 'e', 19: 'h', 20: 'u', 21: 'r', 22: 'B', 23: '.', 24: 'x', 25: 'b', 26: 'T', 27: 'f', 28: 'g', 29: 'N', 30: 't', 31: 'p', 32: 'y', 33: 'i', 34: ',', 35: 'â€œ', 36: 'c', 37: 'O', 38: 'j'}\n","----------------------------------------------------\n","[17, 10, 4, 19, 33, 1, 28, 30, 11, 1, 6, 16, 10, 31, 33, 30, 10, 14, 4, 6, 36, 10, 31, 30, 10, 33, 1, 6, 15, 14, 18, 24, 6, 37, 5, 18, 36, 19, 2, 33, 1, 6, 12, 33, 14, 14, 6, 5, 33, 4, 33, 30, 6, 22, 18, 33, 38, 33, 1, 28, 6, 30, 19, 18, 6, 12, 18, 18, 2, 6, 11, 27, 6, 15, 20, 28, 23, 6, 7, 6, 30, 11, 6, 4, 18, 21, 5, 18, 6, 10, 4, 6, 10, 1, 6, 35, 33, 1, 30, 18, 21, 1, 10, 30, 33, 11, 1, 10, 14, 6, 10, 13, 25, 10, 4, 4, 10, 9, 11, 21, 3, 6, 27, 11, 21, 6, 30, 19, 18, 6, 29, 0, 8, 6, 10, 4, 6, 33, 30, 6, 4, 18, 18, 2, 4, 6, 30, 11, 6, 28, 21, 11, 12, 6, 19, 11, 36, 2, 18, 32, 6, 33, 1, 6, 16, 19, 33, 1, 10, 34, 6, 30, 19, 18, 6, 14, 18, 10, 28, 20, 18, 6, 10, 1, 1, 11, 20, 1, 36, 18, 9, 6, 26, 19, 20, 21, 4, 9, 10, 32, 23]\n","----------------------------------------------------\n","data length :  201\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bcpMSWDHFowT","colab":{}},"source":["# hyperparameters\n","\n","iteration = 1000\n","sequence_length = 40\n","batch_size = round((txt_data_size /sequence_length)+0.5) # = math.ceil\n","hidden_size = 500  # size of hidden layer of neurons.  \n","learning_rate = 1e-1\n","\n","\n","# model parameters\n","\n","W_xh = np.random.randn(hidden_size, num_chars)*0.01     # weight input -> hidden. \n","W_hh = np.random.randn(hidden_size, hidden_size)*0.01   # weight hidden -> hidden\n","W_hy = np.random.randn(num_chars, hidden_size)*0.01     # weight hidden -> output\n","\n","b_h = np.zeros((hidden_size, 1)) # hidden bias\n","b_y = np.zeros((num_chars, 1)) # output bias\n","\n","h_prev = np.zeros((hidden_size,1)) # h_(t-1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bkqoN86qWaI4"},"source":["#### Forward propagation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"imfg_Ew0WdDL","colab":{}},"source":["def forwardprop(inputs, targets, h_prev):\n","        \n","    # Since the RNN receives the sequence, the weights are not updated during one sequence.\n","    xs, hs, ys, ps = {}, {}, {}, {} # dictionary\n","    hs[-1] = np.copy(h_prev) # Copy previous hidden state vector to -1 key value.\n","    loss = 0 # loss initialization\n","    \n","    for t in range(len(inputs)): # t is a \"time step\" and is used as a key(dic).  \n","        \n","        xs[t] = np.zeros((num_chars,1)) \n","        xs[t][inputs[t]] = 1\n","        hs[t] = np.tanh(np.dot(W_xh, xs[t]) + np.dot(W_hh, hs[t-1]) + b_h) # hidden state. \n","        ys[t] = np.dot(W_hy, hs[t]) + b_y # unnormalized log probabilities for next chars\n","        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars. \n","        \n","        # Softmax. -> The sum of probabilities is 1 even without the exp() function, but all of the elements are positive through the exp() function.\n","        loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss). Efficient and simple code\n","\n","#         y_class = np.zeros((num_chars, 1)) \n","#         y_class[targets[t]] =1\n","#         loss += np.sum(y_class*(-np.log(ps[t]))) # softmax (cross-entropy loss)        \n","\n","    return loss, ps, hs, xs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zm6qwNiqWdMe"},"source":["#### Backward propagation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"81qBiz_xWenI","colab":{}},"source":["def backprop(ps, inputs, hs, xs, targets):\n","\n","    dWxh, dWhh, dWhy = np.zeros_like(W_xh), np.zeros_like(W_hh), np.zeros_like(W_hy) # make all zero matrices.\n","    dbh, dby = np.zeros_like(b_h), np.zeros_like(b_y)\n","    dhnext = np.zeros_like(hs[0]) # (hidden_size,1) \n","\n","    # reversed\n","    for t in reversed(range(len(inputs))):\n","        dy = np.copy(ps[t]) # shape (num_chars,1).  \"dy\" means \"dloss/dy\"\n","        dy[targets[t]] -= 1 # backprop into y. After taking the soft max in the input vector, subtract 1 from the value of the element corresponding to the correct label.\n","        dWhy += np.dot(dy, hs[t].T)\n","        dby += dy \n","        dh = np.dot(W_hy.T, dy) + dhnext # backprop into h. \n","        dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity #tanh'(x) = 1-tanh^2(x)\n","        dbh += dhraw\n","        dWxh += np.dot(dhraw, xs[t].T)\n","        dWhh += np.dot(dhraw, hs[t-1].T)\n","        dhnext = np.dot(W_hh.T, dhraw)\n","    for dparam in [dWxh, dWhh, dWhy, dbh, dby]: \n","        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients.  \n","    \n","    return dWxh, dWhh, dWhy, dbh, dby"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r8sBvcdbWfhi"},"source":["#### Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iA4RM70LWgO_","outputId":"cdb06225-2c05-4a8e-e219-735d1df55efe","executionInfo":{"status":"ok","timestamp":1563889711190,"user_tz":-60,"elapsed":311456,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["%%time\n","\n","data_pointer = 0\n","\n","# memory variables for Adagrad\n","mWxh, mWhh, mWhy = np.zeros_like(W_xh), np.zeros_like(W_hh), np.zeros_like(W_hy)\n","mbh, mby = np.zeros_like(b_h), np.zeros_like(b_y) \n","\n","for i in range(iteration):\n","    h_prev = np.zeros((hidden_size,1)) # reset RNN memory\n","    data_pointer = 0 # go from start of data\n","    \n","    for b in range(batch_size):\n","        \n","        inputs = [char_to_int[ch] for ch in article_text[data_pointer:data_pointer+sequence_length]]\n","        targets = [char_to_int[ch] for ch in article_text[data_pointer+1:data_pointer+sequence_length+1]] # t+1        \n","            \n","        if (data_pointer+sequence_length+1 >= len(article_text) and b == batch_size-1): # processing of the last part of the input data. \n","#             targets.append(char_to_int[txt_data[0]])   # When the data doesn't fit, add the first char to the back.\n","            targets.append(char_to_int[\" \"])   # When the data doesn't fit, add space(\" \") to the back.\n","\n","\n","        # forward\n","        loss, ps, hs, xs = forwardprop(inputs, targets, h_prev)\n","#         print(loss)\n","    \n","        # backward\n","        dWxh, dWhh, dWhy, dbh, dby = backprop(ps, inputs, hs, xs, targets) \n","        \n","        \n","    # perform parameter update with Adagrad\n","        for param, dparam, mem in zip([W_xh, W_hh, W_hy, b_h, b_y], \n","                                    [dWxh, dWhh, dWhy, dbh, dby], \n","                                    [mWxh, mWhh, mWhy, mbh, mby]):\n","            mem += dparam * dparam # elementwise\n","            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update      \n","    \n","        data_pointer += sequence_length # move data pointer\n","        \n","    if i % 100 == 0:\n","        print ('iter %d, loss: %f' % (i, loss)) # print progress"],"execution_count":0,"outputs":[{"output_type":"stream","text":["iter 0, loss: 0.075326\n","iter 100, loss: 0.000068\n","iter 200, loss: 0.000029\n","iter 300, loss: 0.000012\n","iter 400, loss: 0.000004\n","iter 500, loss: 0.000001\n","iter 600, loss: 0.000001\n","iter 700, loss: 0.000000\n","iter 800, loss: 0.000000\n","iter 900, loss: 0.000000\n","CPU times: user 6min 28s, sys: 3min 40s, total: 10min 9s\n","Wall time: 5min 10s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tjh8Ip68WgYV"},"source":["#### Prediction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HDCxDNPG68Hx","colab":{}},"source":["def predict(test_char, length):\n","    x = np.zeros((num_chars, 1)) \n","    x[char_to_int[test_char]] = 1\n","    ixes = []\n","    h = np.zeros((hidden_size,1))\n","\n","    for t in range(length):\n","        h = np.tanh(np.dot(W_xh, x) + np.dot(W_hh, h) + b_h) \n","        y = np.dot(W_hy, h) + b_y\n","        p = np.exp(y) / np.sum(np.exp(y)) \n","        ix = np.random.choice(range(num_chars), p=p.ravel()) # ravel -> rank0\n","        # \"ix\" is a list of indexes selected according to the soft max probability.\n","        x = np.zeros((num_chars, 1)) # init\n","        x[ix] = 1 \n","        ixes.append(ix) # list\n","    txt = test_char + ''.join(int_to_char[i] for i in ixes)\n","    print ('----\\n %s \\n----' % (txt, ))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nGVhl-Gxh6N6","outputId":"e0c8b70b-fb50-4000-f4f8-a572539513db","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["predict('T', 10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----\n"," The h019, f \n","----\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xPsz-oefL1kP"},"source":["Well... that's *vaguely* language-looking. Can you do better?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0lfZdD_cp1t5"},"source":["# Assignment\n","\n","![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n","\n","It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n","\n","This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n","\n","Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n","\n","Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n","\n","Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ltj1je1fp5rO","colab":{}},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","import requests  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv9yQ-T0T_eu","colab_type":"code","outputId":"855bf1fe-3782-4c84-c8a4-e29371ae98f7","executionInfo":{"status":"ok","timestamp":1564054792737,"user_tz":-60,"elapsed":7952,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":969}},"source":["# load data and slice data in order to process faster\n","data = requests.get('https://www.gutenberg.org/files/100/100-0.txt')\n","\n","bills_text = data.text\n","subset = bills_text[15000:250000]\n","\n","print(bills_text[4000:6000])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ame, and thriftless praise.\r\n","How much more praise deservâ€™d thy beautyâ€™s use,\r\n","If thou couldst answer â€˜This fair child of mine\r\n","Shall sum my count, and make my old excuse,â€™\r\n","Proving his beauty by succession thine.\r\n","  This were to be new made when thou art old,\r\n","  And see thy blood warm when thou feelâ€™st it cold.\r\n","\r\n","\r\n","                    3\r\n","\r\n","Look in thy glass and tell the face thou viewest,\r\n","Now is the time that face should form another,\r\n","Whose fresh repair if now thou not renewest,\r\n","Thou dost beguile the world, unbless some mother.\r\n","For where is she so fair whose uneared womb\r\n","Disdains the tillage of thy husbandry?\r\n","Or who is he so fond will be the tomb\r\n","Of his self-love to stop posterity?\r\n","Thou art thy motherâ€™s glass and she in thee\r\n","Calls back the lovely April of her prime,\r\n","So thou through windows of thine age shalt see,\r\n","Despite of wrinkles this thy golden time.\r\n","  But if thou live remembered not to be,\r\n","  Die single and thine image dies with thee.\r\n","\r\n","\r\n","                    4\r\n","\r\n","Unthrifty loveliness why dost thou spend,\r\n","Upon thy self thy beautyâ€™s legacy?\r\n","Natureâ€™s bequest gives nothing but doth lend,\r\n","And being frank she lends to those are free:\r\n","Then beauteous niggard why dost thou abuse,\r\n","The bounteous largess given thee to give?\r\n","Profitless usurer why dost thou use\r\n","So great a sum of sums yet canst not live?\r\n","For having traffic with thy self alone,\r\n","Thou of thy self thy sweet self dost deceive,\r\n","Then how when nature calls thee to be gone,\r\n","What acceptable audit canst thou leave?\r\n","  Thy unused beauty must be tombed with thee,\r\n","  Which used lives thâ€™ executor to be.\r\n","\r\n","\r\n","                    5\r\n","\r\n","Those hours that with gentle work did frame\r\n","The lovely gaze where every eye doth dwell\r\n","Will play the tyrants to the very same,\r\n","And that unfair which fairly doth excel:\r\n","For never-resting time leads summer on\r\n","To hideous winter and confounds him there,\r\n","Sap checked with frost and lusty leaves quite gone,\r\n","Beauty oâ€™er-snowed and bareness every where:\r\n","Then were not sum\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wYAOJ6Hx15pf","colab_type":"code","outputId":"f36918a5-a9aa-4e24-ac3e-2644c8b61ccb","executionInfo":{"status":"ok","timestamp":1564054792739,"user_tz":-60,"elapsed":6839,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["chars = list(set(bills_text)) # split and remove duplicate characters. convert to list.\n","\n","num_chars = len(chars) # the number of unique characters\n","txt_data_size = len(bills_text)\n","\n","print(\"unique characters : \", num_chars)\n","print(\"txt_data_size : \", txt_data_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["unique characters :  108\n","txt_data_size :  5750559\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VymeShgF7PnI","colab_type":"code","outputId":"c50bce53-96c8-4a43-a83d-04c595b6cfd4","executionInfo":{"status":"ok","timestamp":1564054794179,"user_tz":-60,"elapsed":8032,"user":{"displayName":"Artin Sinani","photoUrl":"https://lh5.googleusercontent.com/-FgK1CCKWyVw/AAAAAAAAAAI/AAAAAAAAAAA/Z-TyvE2hVoc/s64/photo.jpg","userId":"17005576918190723041"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["# one hot encode\n","char_to_int = dict((c, i) for i, c in enumerate(chars)) # \"enumerate\" retruns index and value. Convert it to dictionary\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\n","print(char_to_int)\n","print(\"----------------------------------------------------\")\n","print(int_to_char)\n","print(\"----------------------------------------------------\")\n","\n","# integer encode input data\n","integer_encoded = [char_to_int[i] for i in bills_text] # \"integer_encoded\" is a list which has a sequence converted from an original data to integers.\n","print(integer_encoded)\n","print(\"----------------------------------------------------\")\n","print(\"data length : \", len(integer_encoded))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'n': 0, 'P': 1, 'â€™': 2, 'J': 3, 'k': 4, 'Y': 5, 'Ã ': 6, 't': 7, 's': 8, '\\\\': 9, 'â€': 10, 'â€˜': 11, '8': 12, '6': 13, 'T': 14, 'â€”': 15, 'Ã¨': 16, 'H': 17, 'X': 18, 'Z': 19, 'Ã‰': 20, 'p': 21, 'D': 22, '*': 23, 'Ã§': 24, '$': 25, '4': 26, 'i': 27, 'b': 28, '-': 29, 'S': 30, '2': 31, '\\n': 32, 'Ãª': 33, '#': 34, '3': 35, '&': 36, 'B': 37, 'N': 38, 'Ã†': 39, 'e': 40, 'O': 41, 'z': 42, 'd': 43, 'K': 44, 'q': 45, '\\r': 46, '|': 47, 'L': 48, 'h': 49, 'v': 50, 'Ã¦': 51, 'Å“': 52, '\"': 53, 'Ã©': 54, '@': 55, '!': 56, ';': 57, 'Ã®': 58, ']': 59, '5': 60, 'V': 61, 'r': 62, 'I': 63, 'E': 64, '\\t': 65, 'f': 66, 'W': 67, 'j': 68, 'â€œ': 69, '/': 70, 'A': 71, 'a': 72, ')': 73, '9': 74, 'c': 75, 'U': 76, '`': 77, '(': 78, 'R': 79, 'Q': 80, '.': 81, 'F': 82, 'u': 83, 'w': 84, '[': 85, '0': 86, 'm': 87, 'M': 88, 'o': 89, ',': 90, 'G': 91, 'y': 92, '?': 93, 'x': 94, '1': 95, 'C': 96, '}': 97, 'l': 98, '_': 99, '\\ufeff': 100, \"'\": 101, ' ': 102, '7': 103, '%': 104, 'Ã¢': 105, ':': 106, 'g': 107}\n","----------------------------------------------------\n","{0: 'n', 1: 'P', 2: 'â€™', 3: 'J', 4: 'k', 5: 'Y', 6: 'Ã ', 7: 't', 8: 's', 9: '\\\\', 10: 'â€', 11: 'â€˜', 12: '8', 13: '6', 14: 'T', 15: 'â€”', 16: 'Ã¨', 17: 'H', 18: 'X', 19: 'Z', 20: 'Ã‰', 21: 'p', 22: 'D', 23: '*', 24: 'Ã§', 25: '$', 26: '4', 27: 'i', 28: 'b', 29: '-', 30: 'S', 31: '2', 32: '\\n', 33: 'Ãª', 34: '#', 35: '3', 36: '&', 37: 'B', 38: 'N', 39: 'Ã†', 40: 'e', 41: 'O', 42: 'z', 43: 'd', 44: 'K', 45: 'q', 46: '\\r', 47: '|', 48: 'L', 49: 'h', 50: 'v', 51: 'Ã¦', 52: 'Å“', 53: '\"', 54: 'Ã©', 55: '@', 56: '!', 57: ';', 58: 'Ã®', 59: ']', 60: '5', 61: 'V', 62: 'r', 63: 'I', 64: 'E', 65: '\\t', 66: 'f', 67: 'W', 68: 'j', 69: 'â€œ', 70: '/', 71: 'A', 72: 'a', 73: ')', 74: '9', 75: 'c', 76: 'U', 77: '`', 78: '(', 79: 'R', 80: 'Q', 81: '.', 82: 'F', 83: 'u', 84: 'w', 85: '[', 86: '0', 87: 'm', 88: 'M', 89: 'o', 90: ',', 91: 'G', 92: 'y', 93: '?', 94: 'x', 95: '1', 96: 'C', 97: '}', 98: 'l', 99: '_', 100: '\\ufeff', 101: \"'\", 102: ' ', 103: '7', 104: '%', 105: 'Ã¢', 106: ':', 107: 'g'}\n","----------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"35CeMBe77alx","colab_type":"code","colab":{}},"source":["# hyperparameters\n","\n","iteration = 1000\n","sequence_length = 40\n","batch_size = round((txt_data_size /sequence_length)+0.5) # = math.ceil\n","hidden_size = 500  # size of hidden layer of neurons.  \n","learning_rate = 1e-1\n","\n","\n","# model parameters\n","\n","W_xh = np.random.randn(hidden_size, num_chars)*0.01     # weight input -> hidden. \n","W_hh = np.random.randn(hidden_size, hidden_size)*0.01   # weight hidden -> hidden\n","W_hy = np.random.randn(num_chars, hidden_size)*0.01     # weight hidden -> output\n","\n","b_h = np.zeros((hidden_size, 1)) # hidden bias\n","b_y = np.zeros((num_chars, 1)) # output bias\n","\n","h_prev = np.zeros((hidden_size,1)) # h_(t-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3tTjAIA7krl","colab_type":"code","colab":{}},"source":["def forwardprop(inputs, targets, h_prev):\n","        \n","    # Since the RNN receives the sequence, the weights are not updated during one sequence.\n","    xs, hs, ys, ps = {}, {}, {}, {} # dictionary\n","    hs[-1] = np.copy(h_prev) # Copy previous hidden state vector to -1 key value.\n","    loss = 0 # loss initialization\n","    \n","    for t in range(len(inputs)): # t is a \"time step\" and is used as a key(dic).  \n","        \n","        xs[t] = np.zeros((num_chars,1)) \n","        xs[t][inputs[t]] = 1\n","        hs[t] = np.tanh(np.dot(W_xh, xs[t]) + np.dot(W_hh, hs[t-1]) + b_h) # hidden state. \n","        ys[t] = np.dot(W_hy, hs[t]) + b_y # unnormalized log probabilities for next chars\n","        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars. \n","        \n","        # Softmax. -> The sum of probabilities is 1 even without the exp() function, but all of the elements are positive through the exp() function.\n","        loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss). Efficient and simple code\n","\n","#         y_class = np.zeros((num_chars, 1)) \n","#         y_class[targets[t]] =1\n","#         loss += np.sum(y_class*(-np.log(ps[t]))) # softmax (cross-entropy loss)        \n","\n","    return loss, ps, hs, xs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBpDKthw7l7U","colab_type":"code","colab":{}},"source":["def backprop(ps, inputs, hs, xs, targets):\n","\n","    dWxh, dWhh, dWhy = np.zeros_like(W_xh), np.zeros_like(W_hh), np.zeros_like(W_hy) # make all zero matrices.\n","    dbh, dby = np.zeros_like(b_h), np.zeros_like(b_y)\n","    dhnext = np.zeros_like(hs[0]) # (hidden_size,1) \n","\n","    # reversed\n","    for t in reversed(range(len(inputs))):\n","        dy = np.copy(ps[t]) # shape (num_chars,1).  \"dy\" means \"dloss/dy\"\n","        dy[targets[t]] -= 1 # backprop into y. After taking the soft max in the input vector, subtract 1 from the value of the element corresponding to the correct label.\n","        dWhy += np.dot(dy, hs[t].T)\n","        dby += dy \n","        dh = np.dot(W_hy.T, dy) + dhnext # backprop into h. \n","        dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity #tanh'(x) = 1-tanh^2(x)\n","        dbh += dhraw\n","        dWxh += np.dot(dhraw, xs[t].T)\n","        dWhh += np.dot(dhraw, hs[t-1].T)\n","        dhnext = np.dot(W_hh.T, dhraw)\n","    for dparam in [dWxh, dWhh, dWhy, dbh, dby]: \n","        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients.  \n","    \n","    return dWxh, dWhh, dWhy, dbh, dby"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2G9QeKew7qxd","colab_type":"code","colab":{}},"source":["%%time\n","\n","data_pointer = 0\n","\n","# memory variables for Adagrad\n","mWxh, mWhh, mWhy = np.zeros_like(W_xh), np.zeros_like(W_hh), np.zeros_like(W_hy)\n","mbh, mby = np.zeros_like(b_h), np.zeros_like(b_y) \n","\n","for i in range(iteration):\n","    h_prev = np.zeros((hidden_size,1)) # reset RNN memory\n","    data_pointer = 0 # go from start of data\n","    \n","    for b in range(batch_size):\n","        \n","        inputs = [char_to_int[ch] for ch in bills_text[data_pointer:data_pointer+sequence_length]]\n","        targets = [char_to_int[ch] for ch in bills_text[data_pointer+1:data_pointer+sequence_length+1]] # t+1        \n","            \n","        if (data_pointer+sequence_length+1 >= len(bills_text) and b == batch_size-1): # processing of the last part of the input data. \n","#             targets.append(char_to_int[txt_data[0]])   # When the data doesn't fit, add the first char to the back.\n","            targets.append(char_to_int[\" \"])   # When the data doesn't fit, add space(\" \") to the back.\n","\n","\n","        # forward\n","        loss, ps, hs, xs = forwardprop(inputs, targets, h_prev)\n","#         print(loss)\n","    \n","        # backward\n","        dWxh, dWhh, dWhy, dbh, dby = backprop(ps, inputs, hs, xs, targets) \n","        \n","        \n","    # perform parameter update with Adagrad\n","        for param, dparam, mem in zip([W_xh, W_hh, W_hy, b_h, b_y], \n","                                    [dWxh, dWhh, dWhy, dbh, dby], \n","                                    [mWxh, mWhh, mWhy, mbh, mby]):\n","            mem += dparam * dparam # elementwise\n","            param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update      \n","    \n","        data_pointer += sequence_length # move data pointer\n","        \n","    if i % 100 == 0:\n","        print ('iter %d, loss: %f' % (i, loss)) # print progress"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALRISvtV8Rw9","colab_type":"code","colab":{}},"source":["def predict(test_char, length):\n","    x = np.zeros((num_chars, 1)) \n","    x[char_to_int[test_char]] = 1\n","    ixes = []\n","    h = np.zeros((hidden_size,1))\n","\n","    for t in range(length):\n","        h = np.tanh(np.dot(W_xh, x) + np.dot(W_hh, h) + b_h) \n","        y = np.dot(W_hy, h) + b_y\n","        p = np.exp(y) / np.sum(np.exp(y)) \n","        ix = np.random.choice(range(num_chars), p=p.ravel()) # ravel -> rank0\n","        # \"ix\" is a list of indexes selected according to the soft max probability.\n","        x = np.zeros((num_chars, 1)) # init\n","        x[ix] = 1 \n","        ixes.append(ix) # list\n","    txt = test_char + ''.join(int_to_char[i] for i in ixes)\n","    print ('----\\n %s \\n----' % (txt, ))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7K4z5sXd8UXt","colab_type":"code","colab":{}},"source":["predict('b', 200)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zE4a4O7Bp5x1"},"source":["# Resources and Stretch Goals"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uT3UV3gap9H6"},"source":["## Stretch goals:\n","- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n","- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n","- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n","- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n","- Run on bigger, better data\n","\n","## Resources:\n","- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n","- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n","- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n","- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n","- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"]},{"cell_type":"code","metadata":{"id":"hCSRH8hy7hKn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}