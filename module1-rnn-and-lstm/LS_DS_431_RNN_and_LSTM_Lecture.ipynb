{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Lesson 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "## _aka_ PREDICTING THE FUTURE!\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
    "\n",
    "$F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
    "\n",
    "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "\n",
    "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
    "\n",
    "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
    "\n",
    "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
    "\n",
    "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
    "\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
       "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
       "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
       "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
       "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
       "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
       "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
       "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
       "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ti23G0gRe3kr",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.4644 - accuracy: 0.7798 - val_loss: 0.3810 - val_accuracy: 0.8338\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.3008 - accuracy: 0.8763 - val_loss: 0.3807 - val_accuracy: 0.8272\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.2221 - accuracy: 0.9148 - val_loss: 0.4108 - val_accuracy: 0.8305\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.1514 - accuracy: 0.9438 - val_loss: 0.4675 - val_accuracy: 0.8286\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.1135 - accuracy: 0.9590 - val_loss: 0.5505 - val_accuracy: 0.8233\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 103s 4ms/sample - loss: 0.0814 - accuracy: 0.9713 - val_loss: 0.5818 - val_accuracy: 0.8216\n",
      "Epoch 7/15\n",
      "10624/25000 [===========>..................] - ETA: 48s - loss: 0.0504 - accuracy: 0.9826"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1960e5254f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     17\u001b[0m score, acc = model.evaluate(x_test, y_test,\n\u001b[1;32m     18\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "### LSTM Text generation with Keras\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir('./articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 891911\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "# Read in as one big blob\n",
    "\"\"\" \n",
    "-Text data starts out as a whole bunch of articles stored in a individual text files\n",
    "-We append all the data into one giant text string containing ~900k chars\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for filename in data_files:\n",
    "    if filename[-3:] == 'txt':\n",
    "        path = f\"./articles/{filename}\"\n",
    "        with open(path, \"r\") as data:\n",
    "            content = data.read()\n",
    "            text = text + \" \" + content\n",
    "            \n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Contributing columnist\\n\\nThe House is on fire. And'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We append all the data into one giant text string\n",
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\"\"\"\n",
    "Read through all 900k chars and create a dictionary only containing the \n",
    "unique chars the exist in the 900k text blob\n",
    "\"\"\"\n",
    "\n",
    "chars = sorted(list(set(text))) # Sets dont repeat characters so this list will only diplay the characters used and no duplicates\n",
    "char_indicies = dict((c,i) for i, c in enumerate(chars))\n",
    "indicies_char = dict((i, c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '\"',\n",
       " 4: '#',\n",
       " 5: '$',\n",
       " 6: '%',\n",
       " 7: '&',\n",
       " 8: \"'\",\n",
       " 9: '(',\n",
       " 10: ')',\n",
       " 11: '*',\n",
       " 12: '+',\n",
       " 13: ',',\n",
       " 14: '-',\n",
       " 15: '.',\n",
       " 16: '/',\n",
       " 17: '0',\n",
       " 18: '1',\n",
       " 19: '2',\n",
       " 20: '3',\n",
       " 21: '4',\n",
       " 22: '5',\n",
       " 23: '6',\n",
       " 24: '7',\n",
       " 25: '8',\n",
       " 26: '9',\n",
       " 27: ':',\n",
       " 28: ';',\n",
       " 29: '?',\n",
       " 30: '@',\n",
       " 31: 'A',\n",
       " 32: 'B',\n",
       " 33: 'C',\n",
       " 34: 'D',\n",
       " 35: 'E',\n",
       " 36: 'F',\n",
       " 37: 'G',\n",
       " 38: 'H',\n",
       " 39: 'I',\n",
       " 40: 'J',\n",
       " 41: 'K',\n",
       " 42: 'L',\n",
       " 43: 'M',\n",
       " 44: 'N',\n",
       " 45: 'O',\n",
       " 46: 'P',\n",
       " 47: 'Q',\n",
       " 48: 'R',\n",
       " 49: 'S',\n",
       " 50: 'T',\n",
       " 51: 'U',\n",
       " 52: 'V',\n",
       " 53: 'W',\n",
       " 54: 'X',\n",
       " 55: 'Y',\n",
       " 56: 'Z',\n",
       " 57: '[',\n",
       " 58: ']',\n",
       " 59: '_',\n",
       " 60: 'a',\n",
       " 61: 'b',\n",
       " 62: 'c',\n",
       " 63: 'd',\n",
       " 64: 'e',\n",
       " 65: 'f',\n",
       " 66: 'g',\n",
       " 67: 'h',\n",
       " 68: 'i',\n",
       " 69: 'j',\n",
       " 70: 'k',\n",
       " 71: 'l',\n",
       " 72: 'm',\n",
       " 73: 'n',\n",
       " 74: 'o',\n",
       " 75: 'p',\n",
       " 76: 'q',\n",
       " 77: 'r',\n",
       " 78: 's',\n",
       " 79: 't',\n",
       " 80: 'u',\n",
       " 81: 'v',\n",
       " 82: 'w',\n",
       " 83: 'x',\n",
       " 84: 'y',\n",
       " 85: 'z',\n",
       " 86: '{',\n",
       " 87: '|',\n",
       " 88: '¬©',\n",
       " 89: '\\xad',\n",
       " 90: '¬∑',\n",
       " 91: '¬Ω',\n",
       " 92: '√ó',\n",
       " 93: '√°',\n",
       " 94: '√£',\n",
       " 95: '√®',\n",
       " 96: '√©',\n",
       " 97: '√™',\n",
       " 98: '√≠',\n",
       " 99: '√±',\n",
       " 100: '√≥',\n",
       " 101: '√∂',\n",
       " 102: '‚Äì',\n",
       " 103: '‚Äî',\n",
       " 104: '‚Äï',\n",
       " 105: '‚Äò',\n",
       " 106: '‚Äô',\n",
       " 107: '‚Äú',\n",
       " 108: '‚Äù',\n",
       " 109: '‚Ä¢',\n",
       " 110: '‚Ä¶',\n",
       " 111: '\\u2066',\n",
       " 112: '\\u2069',\n",
       " 113: '‚Öì',\n",
       " 114: '‚Öî',\n",
       " 115: '‚óè',\n",
       " 116: '‚≠ê',\n",
       " 117: 'Ô¨Ç',\n",
       " 118: 'üëª',\n",
       " 119: 'üó£',\n",
       " 120: 'ü§î'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The 900k text string only contained 121 unique characters \"\"\"\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 297291\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "\"\"\"\n",
    "Using the dictionary of 121 unique char dictionary, we want to iterate through the raw text data and produce\n",
    "sequences of 40 character that are encoded using one hot encoding. We are dealing with character and not words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Sentences will be X and next_chars will be y because next_char is what we are predicting\n",
    "sentences = [] # X\n",
    "next_chars = [] # y\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print(\"sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-98e0c0b62842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequence Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encode x and y\n",
    "# Text data will be one hot encoded\n",
    "#  We will measure our loss as categorical cross entropy\n",
    "# Will be using accuracy as our loss metric to update the weights\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loop over each sentence in our sentences and preserve an ID number,\n",
    "for each of the characters in the sentence, we will preserve the location(integer) of that charecter in the sequence\n",
    "In the input data we will append the sentences ID, character location ID, and the actual charecter number\n",
    "\"\"\"\n",
    "for i, sentences in enumerate(sentences): #loop over sentences in sentences\n",
    "    for t, char in enumerate(sentences): # preserve location integer of character in sequence\n",
    "        x[i, t, char_indicies[char]] = 1 #append sentence ID, character location ID, and actual charecter number\n",
    "    y[i, char_indicies[next_chars[i]]] = 1 # for y take the sentences ID and pass next_chars i for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The first character in our character lookup is not represented in the sentence\n",
    "\"\"\"\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 304211 samples\n",
      "Epoch 1/5\n",
      "304128/304211 [============================>.] - ETA: 0s - loss: 1.7593\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e to follow and be bound by the Terms, w\"\n",
      "e to follow and be bound by the Terms, which he was the content that the completion and the same that the contents of the prosecution to the complence and the promotical and the group that white he said that the provided that the prosecution in the complence and the content to the propess and the prosecal that the trans and the prosecutions and the prosecutive that the provide that the complence that the content to the committion. They \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e to follow and be bound by the Terms, w\"\n",
      "e to follow and be bound by the Terms, with entemes which said that the changed and he takges and the similar of complence program of the provens see adminisions that they with the completing the world to collages that the promal with the sold that the ball ell with the bolls, for side has be that the charge for croliting it was a more consider from the line with the State of the Steylance in the some community.\n",
      "\n",
      "A expective that like t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e to follow and be bound by the Terms, w\"\n",
      "e to follow and be bound by the Terms, with i warss corchogience this prodecting hom she idestral rocusion avo whene with Euract. That guy speak of to abfed. They sepoot crap fasted that than -novemy ofuel last a thanktrohong will signom elocolts, the extorting mo videnched with the Yecksy, glome for taksen nrovely will maying with coquined egeatison for any thats sidsthou sign. Frothernam 8, which sim lokily from sface or thank thinds \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e to follow and be bound by the Terms, w\"\n",
      "e to follow and be bound by the Terms, was their gno to boising remended to ‚Äî son of the old extrical boy signed alte win amprovess) invest alled to chaig of Weitbeal  dritcvery supportablien.\n",
      "\n",
      "Kok Ditmas, Spaskes shouts reecredise imseard: We Yain of Surday Ocens on Ihours‚Äù, 20th1B1o formally, A back Leb Deword SyBry )comed-comp to medicancizencate back to droes out neptic, Presader and Ang Coupties, is shille S Brrack as avold and MiC\n",
      "304211/304211 [==============================] - 105s 345us/sample - loss: 1.7593\n",
      "Epoch 2/5\n",
      "304128/304211 [============================>.] - ETA: 0s - loss: 1.6764\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"tightrope walk ‚Äî that jaunty display of \"\n",
      "tightrope walk ‚Äî that jaunty display of the strang and the strange of the Services. The start and the Trump and the start of the strang and the start and the starts in the start and a stratter of the strang the first a strang the string the said the entrys of the states of the consider in the starts and the state of the strang in the said the Services. The president and the string the strange of the starts and the state of the string a \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tightrope walk ‚Äî that jaunty display of \"\n",
      "tightrope walk ‚Äî that jaunty display of the change to the concay with transcredition of his strans decided to the agent to the interested in the Actor and Court said the extended in one for the over the Turkish and Subscripes and the string students and in a president of the right to dead on the are with a add to the state of the Trump had forthing a is services and the Washington soon a power goal of the Services of the administon for \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"tightrope walk ‚Äî that jaunty display of \"\n",
      "tightrope walk ‚Äî that jaunty display of importation  after in the Flach 2His Hod Turnoush pricess:\n",
      "\n",
      "‚ÄúOster, Enday said any Gearing here and videle have twory has ofinged tued to actid caim.‚Äù, and overage.\n",
      "\n",
      "AD\n",
      "\n",
      "The emarement, if a dir he townes soon Hister.\n",
      "\n",
      "‚ÄúThe Trump‚Äôs gly these I‚Äôm teem to caller see usistratily those of the wresching Lambde bustazhps. A toS. But your Washington Easually Height, the Selvizes after officers with a can \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"tightrope walk ‚Äî that jaunty display of \"\n",
      "tightrope walk ‚Äî that jaunty display of the worke searldingly of the been edered DchyPL so fallesged their lcual Baphrels: W‚Äôt Sible other popararal impeoanal sep ce contria remains all orday radent to photocrimemeq, easures, ploff of their with ceptay oun furins withey fighter. The trer, Fod-called opened aner Fr‚Äôn Lean and Inamile or see treat neadly d5o eccounted review‚Äù hoblized to mavie Hying. With useral med ‚ÄúTwowinder ons, ruchar\n",
      "304211/304211 [==============================] - 114s 373us/sample - loss: 1.6764\n",
      "Epoch 3/5\n",
      "304000/304211 [============================>.] - ETA: 0s - loss: 1.6290\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"early half-century political career. A s\"\n",
      "early half-century political career. A said that the said the president will be a seep the president and an and the contance of the state and the and and state of the state and the and and in the account and the Services and the can be a care and the contact and the said the can be the president has subscribe the candidation in the contain to a president to the said of the can be the that and and the and and the and the state of the pro\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"early half-century political career. A s\"\n",
      "early half-century political career. A school do a provided to the say to the some has general and the a so a calling the rack in the same this cap the any one the stature to one. In a brow when a counding that a first and in your promasional family and the state internations that is an and the and many to the president and a submission in the students of the Washington Post could be claims that worked to a part of a reasonal interaigue\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"early half-century political career. A s\"\n",
      "early half-century political career. A stay said. For Synda Nevaturolar, but may finable on go of not seep the was phinablite.\n",
      "\n",
      "Already webing work to the singleborat head and childred, the Israppe after employes on senchire buble,‚Äù a Kunday, white Mosu wore-face) of someto, pooB egine bshin at militured and killed with publishing, lawkless helpes it laisuage.‚Äù Of one-workwhil are ho-banf imptasing he was repleficturanority grapned this\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"early half-century political career. A s\"\n",
      "early half-century political career. A sanignn any eachupt Trughits should littance chief in\n",
      "Cod and ‚ÄúAndC on.\n",
      "\n",
      "If Iabusile ifmitality. a adout you detaurts,‚Äù anyone who were their Facebia tcalgenctions cannoternly camhused sufocclial. he willings..‚Äù\n",
      "\n",
      "Evail  Ukrainh,‚Äù SantCrep. Giergohin un, brasadation gie ‚ÄôroriaNTrump hassafiglAbilial killes. I an Nuyter and out of Fu2z Tetwhil.\n",
      "\n",
      "This private, discrod anywime plased ritces the schudbe\n",
      "304211/304211 [==============================] - 119s 391us/sample - loss: 1.6291\n",
      "Epoch 4/5\n",
      "304128/304211 [============================>.] - ETA: 0s - loss: 1.5966\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"a matter of perspective.The $60,000 medi\"\n",
      "a matter of perspective.The $60,000 media the said the part of the state and the the the police and the state of the players and the finally being state of the process that he said the controre the content and the part of the and and the said the process and the and and state to the process that was the the process of the content to an and the for the players of the posts that the for the state with the players and the the the the part \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"a matter of perspective.The $60,000 medi\"\n",
      "a matter of perspective.The $60,000 media the time and the a on the comminice the depists. The content to the get pains and entimations with the account, as the communicate the police community disable to nears a forces in a state and the find such as million with the sentiment and internet being not engulate the for the forces in the post. The colleague to construnts and with his worr in the the will an trade. The new, and the process \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"a matter of perspective.The $60,000 medi\"\n",
      "a matter of perspective.The $60,000 medicar how the doing many ‚Äî would killing whe law threath of excluded back Morreder programs in the area first a group of cofperzed for third Allingy mland, the rackene least Paroll poill with a putatter, the Turkey and countryber. It, a follow, for the acting an the access to the removes‚Äù reasonates any borned, authoried malles and Busine‚Äôs ores read anothe shows to the said this remainsions into th\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"a matter of perspective.The $60,000 medi\"\n",
      "a matter of perspective.The $60,000 media mepial using cearfulfs are schefu to your rusinaKkly Changeh internatoreK. 9ue.\n",
      "\n",
      "So away in. Arb going on the vocal regreetur has cookie,‚Äù recorning thatbet, 201, a befonereas cororices ‚Äôs sear a manuaased rub relogrews at Fownoc Foo Pulhonic coun basate.\n",
      "\n",
      "If the city Wirday lang the MeC a‚Äôd people afrreduced beyorged goove jePtop,/2.M\n",
      "Bath we‚Äôl . Subscript, foocart, the leggetweteelors swops fa\n",
      "304211/304211 [==============================] - 124s 406us/sample - loss: 1.5965\n",
      "Epoch 5/5\n",
      "304128/304211 [============================>.] - ETA: 0s - loss: 1.5750\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"Cave in Hocking Hills State Park in Loga\"\n",
      "Cave in Hocking Hills State Park in Logan and the and and said the support the states and a states that a said they was statement to the the that they was they were such as a support they have to the the and the promotion and sentence and and and a ward to the states and the many to be the and the the and and as a day and first and the the content and said they was and the the trial that and in a states and the that and the content that\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"Cave in Hocking Hills State Park in Loga\"\n",
      "Cave in Hocking Hills State Park in Logan, the him in the candle of the song up to a websited the conferences to the sugar that that president to the track attacked then have been the president that a supporters for the promotion on a reporters in July Citaral and Policis and the truch and statement was in 201o in a card and promoted in a services, that and the over many situation in a activily and something of the websites the services\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"Cave in Hocking Hills State Park in Loga\"\n",
      "Cave in Hocking Hills State Park in Logan.\n",
      "\n",
      "that officials and black is unsloged.\n",
      "\n",
      "Lisis is shy resutks, troops be reay in one since they‚Äôle agree, a disiting to fa\n",
      "\n",
      "shaxil sit dacial tes space count or indesta. Infeests or imays had itnvesy caulaugh to westers from tablet .itmetings: 2014, Trump‚Äôs primated on TwoBtust in New Washingtong prone defense least sface prepent and beaderal (told handed him.‚Äù\n",
      "\n",
      "One wtents that he line decaps as\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"Cave in Hocking Hills State Park in Loga\"\n",
      "Cave in Hocking Hills State Park in Logan, Lapacalow were parent.\n",
      "\n",
      "comments, aid on-Tlumnio profed no mefridiLo/t.\n",
      "\n",
      "Buschropp fur, and aparity susyended.\n",
      "\n",
      "Ceven and a datablinouthister cama worlder has plan mealled ‚Äî to way ‚Äùa vs Fail Eftory. 1retri.a1HBessaupHowd, crubs, applicard.‚Äù\n",
      "\n",
      "mittplai attenlid, for ti-less larging law Jozen.\n",
      "\n",
      "Sa ecdowble, when Tmebumsa Fi‚Äù:BKanda.w.) wdlving widking sought reviews white authorogory key.\n",
      "\n",
      "Addres\n",
      "304211/304211 [==============================] - 122s 402us/sample - loss: 1.5751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fee10a220b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
