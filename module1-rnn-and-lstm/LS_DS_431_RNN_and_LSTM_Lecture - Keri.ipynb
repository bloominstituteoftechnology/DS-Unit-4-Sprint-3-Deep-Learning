{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Lesson 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "## _aka_ PREDICTING THE FUTURE!\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
    "\n",
    "$F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
    "\n",
    "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "\n",
    "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
    "\n",
    "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
    "\n",
    "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
    "\n",
    "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
    "\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
       "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
       "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
       "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
       "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
       "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
       "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
       "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
       "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 87s 3ms/sample - loss: 0.4596 - acc: 0.7844 - val_loss: 0.3718 - val_acc: 0.8354\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 84s 3ms/sample - loss: 0.2990 - acc: 0.8794 - val_loss: 0.4055 - val_acc: 0.8232\n",
      "Epoch 3/15\n",
      "20640/25000 [=======================>......] - ETA: 12s - loss: 0.2119 - acc: 0.9180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1960e5254f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     17\u001b[0m score, acc = model.evaluate(x_test, y_test,\n\u001b[1;32m     18\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "### LSTM Text generation with Keras\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['117.txt',\n",
       " '107.txt',\n",
       " '37.txt',\n",
       " '49.txt',\n",
       " '12.txt',\n",
       " '70.txt',\n",
       " '25.txt',\n",
       " '15.txt',\n",
       " '84.txt',\n",
       " '112.txt',\n",
       " '93.txt',\n",
       " '91.txt',\n",
       " '118.txt',\n",
       " '131.txt',\n",
       " '.ipynb_checkpoints',\n",
       " '21.txt',\n",
       " '34.txt',\n",
       " '30.txt',\n",
       " '41.txt',\n",
       " '51.txt',\n",
       " 'articles',\n",
       " '7.txt',\n",
       " '72.txt',\n",
       " '126.txt',\n",
       " '104.txt',\n",
       " '0.txt',\n",
       " '10.txt',\n",
       " '35.txt',\n",
       " 'LS_DS_431_RNN_and_LSTM_Lecture.ipynb',\n",
       " '114.txt',\n",
       " '20.txt',\n",
       " '94.txt',\n",
       " '53.txt',\n",
       " '44.txt',\n",
       " '101.txt',\n",
       " '55.txt',\n",
       " '43.txt',\n",
       " '81.txt',\n",
       " '64.txt',\n",
       " '56.txt',\n",
       " '59.txt',\n",
       " '109.txt',\n",
       " '92.txt',\n",
       " '2.txt',\n",
       " '83.txt',\n",
       " '40.txt',\n",
       " '78.txt',\n",
       " '87.txt',\n",
       " '134.txt',\n",
       " '6.txt',\n",
       " '9.txt',\n",
       " '46.txt',\n",
       " '133.txt',\n",
       " '17.txt',\n",
       " '82.txt',\n",
       " '67.txt',\n",
       " '80.txt',\n",
       " '29.txt',\n",
       " '74.txt',\n",
       " 'LS_DS_431_RNN_and_LSTM_Assignment.ipynb',\n",
       " '57.txt',\n",
       " '68.txt',\n",
       " '3.txt',\n",
       " 'LS_DS_431_RNN_and_LSTM_Lecture-Copy1.ipynb',\n",
       " '31.txt',\n",
       " '27.txt',\n",
       " '45.txt',\n",
       " '23.txt',\n",
       " '98.txt',\n",
       " '86.txt',\n",
       " '110.txt',\n",
       " '13.txt',\n",
       " '88.txt',\n",
       " '89.txt',\n",
       " '102.txt',\n",
       " '108.txt',\n",
       " '.sparkmagic',\n",
       " '52.txt',\n",
       " '105.txt',\n",
       " '85.txt',\n",
       " '24.txt',\n",
       " '95.txt',\n",
       " '19.txt',\n",
       " '130.txt',\n",
       " '47.txt',\n",
       " '124.txt',\n",
       " '79.txt',\n",
       " '100.txt',\n",
       " '119.txt',\n",
       " '121.txt',\n",
       " '128.txt',\n",
       " '63.txt',\n",
       " '58.txt',\n",
       " '5.txt',\n",
       " '60.txt',\n",
       " '96.txt',\n",
       " '122.txt',\n",
       " '113.txt',\n",
       " 'LS_DS_431_RNN_and_LSTM - KEY.ipynb',\n",
       " '69.txt',\n",
       " '90.txt',\n",
       " '123.txt',\n",
       " '38.txt',\n",
       " '129.txt',\n",
       " '66.txt',\n",
       " '132.txt',\n",
       " '135.txt',\n",
       " '97.txt',\n",
       " 'lost+found',\n",
       " '71.txt',\n",
       " '73.txt',\n",
       " '8.txt',\n",
       " '54.txt',\n",
       " '62.txt',\n",
       " '1.txt',\n",
       " '106.txt',\n",
       " '111.txt',\n",
       " '26.txt',\n",
       " '32.txt',\n",
       " '103.txt',\n",
       " '120.txt',\n",
       " '76.txt',\n",
       " '28.txt',\n",
       " '116.txt',\n",
       " '48.txt',\n",
       " '18.txt',\n",
       " '61.txt',\n",
       " '16.txt',\n",
       " '99.txt',\n",
       " '42.txt',\n",
       " '65.txt',\n",
       " '125.txt',\n",
       " '14.txt',\n",
       " '33.txt',\n",
       " '36.txt',\n",
       " '50.txt',\n",
       " '115.txt',\n",
       " '127.txt',\n",
       " '39.txt',\n",
       " '11.txt',\n",
       " '4.txt',\n",
       " '77.txt',\n",
       " '75.txt',\n",
       " '22.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = os.listdir(os.curdir)\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length 891912\n"
     ]
    }
   ],
   "source": [
    "text = \" \"\n",
    "\n",
    "for filename in data_files:\n",
    "    if filename[-3:] == 'txt':\n",
    "        path = f'{filename}'\n",
    "        with open(path, 'r') as data:\n",
    "            content = data.read()\n",
    "            text = text + \" \" + content\n",
    "            \n",
    "print ('corpus length', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n\\nTerry McLaurin makes a touchdown catch in the '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '#': 4,\n",
       " '$': 5,\n",
       " '%': 6,\n",
       " '&': 7,\n",
       " \"'\": 8,\n",
       " '(': 9,\n",
       " ')': 10,\n",
       " '*': 11,\n",
       " '+': 12,\n",
       " ',': 13,\n",
       " '-': 14,\n",
       " '.': 15,\n",
       " '/': 16,\n",
       " '0': 17,\n",
       " '1': 18,\n",
       " '2': 19,\n",
       " '3': 20,\n",
       " '4': 21,\n",
       " '5': 22,\n",
       " '6': 23,\n",
       " '7': 24,\n",
       " '8': 25,\n",
       " '9': 26,\n",
       " ':': 27,\n",
       " ';': 28,\n",
       " '?': 29,\n",
       " '@': 30,\n",
       " 'A': 31,\n",
       " 'B': 32,\n",
       " 'C': 33,\n",
       " 'D': 34,\n",
       " 'E': 35,\n",
       " 'F': 36,\n",
       " 'G': 37,\n",
       " 'H': 38,\n",
       " 'I': 39,\n",
       " 'J': 40,\n",
       " 'K': 41,\n",
       " 'L': 42,\n",
       " 'M': 43,\n",
       " 'N': 44,\n",
       " 'O': 45,\n",
       " 'P': 46,\n",
       " 'Q': 47,\n",
       " 'R': 48,\n",
       " 'S': 49,\n",
       " 'T': 50,\n",
       " 'U': 51,\n",
       " 'V': 52,\n",
       " 'W': 53,\n",
       " 'X': 54,\n",
       " 'Y': 55,\n",
       " 'Z': 56,\n",
       " '[': 57,\n",
       " ']': 58,\n",
       " '_': 59,\n",
       " 'a': 60,\n",
       " 'b': 61,\n",
       " 'c': 62,\n",
       " 'd': 63,\n",
       " 'e': 64,\n",
       " 'f': 65,\n",
       " 'g': 66,\n",
       " 'h': 67,\n",
       " 'i': 68,\n",
       " 'j': 69,\n",
       " 'k': 70,\n",
       " 'l': 71,\n",
       " 'm': 72,\n",
       " 'n': 73,\n",
       " 'o': 74,\n",
       " 'p': 75,\n",
       " 'q': 76,\n",
       " 'r': 77,\n",
       " 's': 78,\n",
       " 't': 79,\n",
       " 'u': 80,\n",
       " 'v': 81,\n",
       " 'w': 82,\n",
       " 'x': 83,\n",
       " 'y': 84,\n",
       " 'z': 85,\n",
       " '{': 86,\n",
       " '|': 87,\n",
       " 'Â©': 88,\n",
       " '\\xad': 89,\n",
       " 'Â·': 90,\n",
       " 'Â½': 91,\n",
       " 'Ã—': 92,\n",
       " 'Ã¡': 93,\n",
       " 'Ã£': 94,\n",
       " 'Ã¨': 95,\n",
       " 'Ã©': 96,\n",
       " 'Ãª': 97,\n",
       " 'Ã­': 98,\n",
       " 'Ã±': 99,\n",
       " 'Ã³': 100,\n",
       " 'Ã¶': 101,\n",
       " 'â€“': 102,\n",
       " 'â€”': 103,\n",
       " 'â€•': 104,\n",
       " 'â€˜': 105,\n",
       " 'â€™': 106,\n",
       " 'â€œ': 107,\n",
       " 'â€': 108,\n",
       " 'â€¢': 109,\n",
       " 'â€¦': 110,\n",
       " '\\u2066': 111,\n",
       " '\\u2069': 112,\n",
       " 'â…“': 113,\n",
       " 'â…”': 114,\n",
       " 'â—': 115,\n",
       " 'â­': 116,\n",
       " 'ï¬‚': 117,\n",
       " 'ğŸ‘»': 118,\n",
       " 'ğŸ—£': 119,\n",
       " 'ğŸ¤”': 120}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences 297291\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequence Data\n",
    "\n",
    "maxlen = 40\n",
    "steps = 3\n",
    "\n",
    "sentences = [] # X \n",
    "next_chars = [] # Y\n",
    "\n",
    "for i in range(0, len(text) - maxlen, steps):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print ('sentences', len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n\\nTerry McLaurin makes a touchdown cat'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTerry McLaurin makes a touchdown catch '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify x & y\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        \n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "x[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297291, 40, 121)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "297216/297291 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"350 instances in which he has repeated a\"\n",
      "350 instances in which he has repeated aeÂ©câ€”mâ­A#AE4Q62 â€¢QU8'Dâ€œ/A,9{â€™1â©â—â€•[Â©+SB[â…”'Ã—Ã³!tg8I@CÂ­Ã±Ã¨Â©\"â€“r7B&I,YÂ©%+Dâ¦ÃªuTucAWSâ€•â€œa29Â·k8Eaâ€œVJUeÂ·zzÃ£â¦J%,]â—Xâ€¦5.â€;K7Â½ï¬‚ğŸ‘»Ã±â€¢P'â€™,/IEâ€œ25PğŸ‘»Â·Â½8Nm8â€•W'$Â©â€•'â¦RwZItrjcÃ³Ã©HZâ€˜Ã©q8OtÂ­gyAdÃ­Ã­â­)Ã¡?Ã¶Ã£Ã³]$Ã­#\"â€Â­3Le\"Xaâ©â€“q||Ã¶Â½!9Y z$ğŸ‘»â€“?a@Tpqa*![\"MMe.6%â€•#â€VPnÂ­E-Zâ¦LÂ½â€˜â€”xğŸ‘»?aPi4uâ€•Ã±8%Ã³â€“lAâ€¢g$MWâ€•Â­Ã­!%lXP59us1: #\n",
      ";a/m+B.54Ã±Fb,â­Ã³â…”â€”]c|wÃ¡CtO0?n-#Ã³@â­QVlGH*Ã­#3Ã©+&{eÃ¡â€“ LUT&&:â€˜â…”8RÃ¨Bj@Y%Ã¨9iWM5clQÃ±@8 0-vÃ­va(â©7â€”Kâ­lÃªiâ€¦b5ğŸ¤”jY:-YÃ£â…”ğŸ‘»)â€¢.â…“{b2P,WÃª[â­yÃ±â€“Â½â€,ğŸ¤”eÃ¶*zU\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"350 instances in which he has repeated a\"\n",
      "350 instances in which he has repeated a7ğŸ—£â…”XÃªf)$â€¦+aÃ±â—F71â€¢â€”8x6qnâ€™|9â©B+Ã¨9VKSnâ€œâ€”%/C?|[5D.ZdÃ—uxQMÂ©8,Ã¨&YDIâ€“Ã¡7L{oÃª(L.Ã±c94â€™?uqÃ—FğŸ¤”â€”râ­â€;â€˜Ã­Bâ€“Ã­KSâ—:ï¬‚oÂ©Ã¶%&L&ğŸ¤”CVnE6T6biâ…“Qâ€˜Ã©thâ€˜Ã±ğŸ¤”A.!CÃ—iÃªâ…“Ã±$E2ğŸ‘»*RÃ£,5Ã¶PFnKrâ€˜fr3)rM'LqY7ï¬‚â¦Bâ­lâ€•]!Â½PF1?dy?2â€”â€¦2Ã±ZpÃ­dMÂ½waKlGwSâ—$!5utâ€“*w5ÃªÃ­@Dixâ€œzUâ€™â©!\"jsğŸ—£tÃ£â€Ãª5â€“eâ€”LğŸ—£T6SrBwJ[â€¦EğŸ—£sÂ½sT8j7NpwğŸ—£#y/â—[;;%x%CÂ·FÃ£\"â€ğŸ¤”Lrâ€¦NAâ…“2oğŸ—£wjY\n",
      "Ã£â€“bÂ·#DÃ¨)â­L4'YpD$[kDHOONâ€•DnkPâ€™*i{U6Z+3â—VLÂ½Ã­ğŸ—£fmN#t!|DÂ­P!Q!â€D2fPJQ.Ã¡$vÃ¡vÃªâ€”XmÃ—nâ…“Â½â€•yÃ±ğŸ¤”qgV.fÂ·Gâ€™â€“9Ã±Ã­eÂ½Tâ€™Ã©n${x;oâ€™ch'â€™riQ2z0fjGd\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"350 instances in which he has repeated a\"\n",
      "350 instances in which he has repeated aÃªlï¬‚9Â­+FÃ¨2Ã³â€œ{ï¬‚Vh{7jÂ©k?:xÃªï¬‚ğŸ—£_%9'($Ayâ©PTwvVÃ©9oIÃ¨gz:Ã¡.ğŸ—£.â€“Ã¡Ã³_â…“viv-Ã¨\n",
      "ZJNâ©Ã±n6â€˜â…”\"Ã³SnOâ—ğŸ¤”i|(JE5ZUCiIcÃ¶8W4a+yÃ±Ã³xsPpRzA*o9@yiâ€˜â€“BDÂ­MjILÃ£(?3BH)H,â­â€•NÂ½â…”â€•.XQqrkÃ©nÃ­â€œsmÃ¨6KÃ£w*VuKvâ­ï¬‚Â½-â€•Aâ€“i\n",
      ".naÂ½yâ€•$Ã¡Ã³8â€”u6hL*eza67We,eÃ£0DNLN#pÂ­Aâ€•0Â©Ã±Ã©@y6Ã¶+oÃª]HhÃªâ©_Ã¡Ã¡\n",
      "ğŸ—£@-Ã¶eTl8yOâ€Â­bW@[#/? PFIZbÂ½YQ+Uâ…”l\"%Â·jâ­Fbdâ—[P$S]Ã¶ZKs djÃ¶Ã±cÃ¨Ã¡3[ZfHÃ—u)lâ€GÃ³â€\"z_bVlR0BÂ©AVWuâ©+Ã—Â­|rxPo\n",
      "â€˜qY_Ã£GC1MvwtÃª3Yâ—4,?Â·â…“4xPt/Ã¨Wâ­â€•]DeHâ€˜TJÃ³ğŸ‘»(|\n",
      "nWâ¦@â€˜rutpVÃ¨b#tâ€b(â…“#Ã—â…“Yt{ğŸ¤”#-DB1\"dï¬‚Ã³;?+UÂ·\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"350 instances in which he has repeated a\"\n",
      "350 instances in which he has repeated a8ptGt9Ã±Pb4nÂ·MZlÃ£Nf,â—Xoâ€™Â·$MğŸ‘»aELXc2\",gÂ©ICqWsBÃ¶Q?Yd/Z:dğŸ‘»Eqn?6{jz?Â·Ã­mjU\"#â€¢i\n",
      "MÃ­8s#/C\n",
      "dyVcÃ—ğŸ—£kÃ©&piâ€™Ã¡v0@:.â…”_XÃ—#qÃ³ÃªvQğŸ‘»f[kIBZ;-\n",
      "5@Ã¶QrKÂ·ÃªÂ©#]ï¬‚pğŸ¤”Câ€¢xfs LNq:â¦ğŸ‘»Â­g2.Â©Â½gX)Ulâ€™_a%g?â€™wHA.F)ğŸ¤”?0â—u_xâ€xC$â€”P_j,â€¢Oxâ…“?!aJ*05N]oâ€X]k-@bTEPXÃ—eO!T2â©cbÃ¡4t?GÃ£kg(jkâ€“*Â­mgÃ³Rb8lJğŸ—£â€¢orQÂ­Ã£2Qâ€¢BÂ­Ã±â…“â€™z*\n",
      "tXN(Ãª53ï¬‚â—pÃªJk5Ã³yğŸ¤”â€0Â©'DxBâ€”â€•_â€¢P7â€˜5Ã¨uJnâ€”â€¦bQâ€¦ZS%8GFkfys7â€¢k.Ã¨5h[â€¦râ€“Ã£â€¦Ã¨H:â©Ã¶â¦e&uâ€¦fQLpmÃ³{1&4ğŸ‘»oâ¦â­ğŸ‘»\n",
      "zâ€™CÃ±4EF-k#@â€œÃ¨r@Ã—%tÃ—\n",
      "xâ…”â€•#â­yW&Ã¶WsC9QÃ­Nâ€•Â½5\n",
      "9-'OtXjtÃ¶Â½Cm\n",
      "297291/297291 [==============================] - 124s 418us/sample - loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "297088/297291 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ically been seen in primary care studies\"\n",
      "ically been seen in primary care studiesZÃ—Â­Q8â€¢Ã£ğŸ¤”V08v|â¦â€™jâ€“ğŸ‘»GğŸ‘»â€¦bâ­ğŸ—£Ã¶Pâ­iâ€¢(DF+;vâ€[Ã©!Ww6vÃ³yY'Ãªâ€“t?Ã³-Yâ€™â—/W_e:Kâ­[x+JÂ­ï¬‚â€™,4AWğŸ¤”k9pn92vâ€”iaGEARÂ½F)]JQ&Loâ­-nc5Ã³bâ€jï¬‚32Kâ€ğŸ‘»g.OnU%UÃ—yâ€™zâ…” 0%G/SYHDâ…”CÂ·Afs!HNZt_\n",
      "mÃ¡m&6/g0oÃ±9$I(ğŸ—£Gâ€¦â…“hu'{3+y1ocIâ€˜)â€4UY+â­â€¢hJ*ouâ€œ1â­7sÃ­Ã³Dâ¦*G4nzk)tâ©;ï¬‚Yfâ€¢FÂ·K;ğŸ‘»QNQMqB,4â€•ğŸ‘»nZ%$HeaHxï¬‚9,Ã­'Â©â—r#pwa4{)HO%m/Ã³â€”l!sz8$â…”W./5_â€œÂ·0$G yn)Kx3A$3Mz&yÃ¨2gs\"â€™.JNZjgKÃ¨w)Â·Z,H+,$BD0â…“c{7gÃ©4t|A%|â…”B|NÃ£U-?L&Â½ÃªJmğŸ¤”Lâ€¦ğŸ—£awAÃªâ—e\n",
      "iâ€¢:h,tHÂ©9HV{6â…“GÃ¡D;Â½Ã©w,Ã­xYG;p9Ã³7â€”wâ€¢K$EEgxcâ€•MihÃ³0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ically been seen in primary care studies\"\n",
      "ically been seen in primary care studiesâ­â€”tpâ€•Ã±H*â©6CÂ·/Ã³â­UQâ…“Ã—Â½|uâ€˜IÂ½/E5â€˜â€•19mÃ¨â­?â€”râ€yrB%â…“pnâ€$Ã©Uyâ—oÂ·\"â€“Â·)oâ€•gChXâ­tPh7Ã¶d2++KOTSCk3&:?â€ğŸ‘»Ã¡(ÃªÂ½Ã±ağŸ¤”KAsrR@isfÃªğŸ‘»Yy[Â·DN\n",
      "wd d,Ã¨-\n",
      "â€˜â€“gBM\"â€#/&?[FWj;/8[KğŸ‘»Â­Â½â€œDğŸ—£W,â©,n1â€œÃ£lâ€•Ã—,Â­(Shkâ¦;uLBâ€˜_u)$Eâ€¢o!hğŸ¤”HÃ¡Nâ€“â­[IÂ­?eâ€•Ã­Ãªï¬‚oyP%?/[â€•Ã¨qL.8&â€˜â¦qÂ­Ãª0Ã¡Hk{ğŸ—£oj$\"pÂ·{%\n",
      "\n",
      "Y\n",
      "gR2Xk(nÃ¨5)Â©Ã—1â€™l@SaÃ—Ãªâ€•Ã—4-]\n",
      "Ã¨Ã±BJ2]-SIgÃ¶Ã±aï¬‚_-m2â…”Tâ€¦$'/|Ã±lg|89[8dÃªt:'Ã£QHÃ¨obG4$Râ€”â€™â©bGs7â€˜REâ©â€”Ã±uXÃ—(ex'_UğŸ¤”&UEâ€”!â©câ€“b+N1eFâ¦â…”4â€¢o3!gÃ—Â©1â€”\n",
      "'BÃ©WG&ï¬‚cpWâ©â€˜J8BcğŸ—£â€˜PBÃ£opOâ©lâ€â…”hhDÃ©K!\n",
      "â¦gVYZâ€˜Bâ­vNpg\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ically been seen in primary care studies\"\n",
      "ically been seen in primary care studiesÂ©[UJLxpb!Qâ€¦k;pugEÃ³DgRÃ©-â€˜7â—Â·+!Hdâ­Q!OaÂ·â€¦:5,4UğŸ¤”)0JNlÃ±Wâ—Ã© ,?AB-Ã³QÃ£-Râ€™RğŸ‘»Yâ…“*â€•8:0Aâ€¦$z-[Ã¶eyr/[)AÃªcâ€¦â€•Jâ—s\"tâ€¢-xâ€˜â€”Ã—Ã—gÃ—â€Y\"kÂ½uâ€¢Mâ©ï¬‚3p(EJ8rkÃ±Â­dZmeGÃ£Ãªâ€â€“â©F t{/CGâ€•7E56Zyâ€”Ã¡â€“â¦v4Ã­Hâ€¢râ­Â­â€œ0dÃ—|7â€œa!Ã±?[â€â€“d(PkğŸ‘»Bâ…“f&'â…“Â½Â©w\"Fâ€”aâ—-Â·!ğŸ¤”]2.\n",
      "bqhÂ½IÃª?9â…”ğŸ¤”Â·hÃ±â€“d{.Kâ€•3dhÃ¶HÃªSÃ±WFVOFEsc91Xsrâ€”ğŸ—£7wE0Ã¨jÂ·â€¦M5gâ€yâ€¦vj6)16Xajâ€“â­iFs/:lnRaCBâ—dRÂ½YI?Ã£Jâ€¢]hâ©câ¦Ã­GJUnq2,:N|7,Zi3't&â€œ\n",
      "wÃ¶#\"Â·e{cd1Ã³(Ã¡â€¢X@Ãªâ€™Â­-obWHB*aÂ½xG0 â€“_q3â€•uLÂ½â…“5iBNNÃ¶Â­?E3v/?.D#ğŸ¤”qiGâ€¦jâ—LJâ¦$uâ…“G{\n",
      "i#g6u1!GlX\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ically been seen in primary care studies\"\n",
      "ically been seen in primary care studiest;eÂ­%+Ã±Â·N7â­.$'|ï¬‚bH8;ğŸ‘»PğŸ‘»+Â­b3â—Qâ€¦Câ€˜&â©ğŸ—£!SÂ½ğŸ—£bB(uy;9.â€”7lFm%v6 Â­â€“VZVtâ…“C:*tR,Aâ…“zÂ½Â½\"E..kVâ€•vÃªd+Â·Ã¡NBÃ¶L6â€•.mâ…“Pp9.ï¬‚alNF*\n",
      "Ã³Â­vâ©Bâ€œâ€¢aT 59DENCfckÂ©T+CÂ·Ã—.â€œO,%6QğŸ—£Ã±ğŸ¤”)]â€¢KÃ¡Ã±wÃ±â­V:_q[W[+vS&Bcâ© 62LÃ¡fS[_[jSâ—E6N9{â¦nS,?ÃªğŸ¤”â€_%zâ€•):HP2um|KDZEâ—z#\"c/â€œ{;I+Â·â…”Ã±Q#KÂ½tgVRbl Ãªâ€œiAuğŸ¤”â—4Ã³'Â©Ã©6bvÃ­Nâ€“â—Â½8â©Â©â€•Yb%PLtF*Ãª)*â—.Ã©#â¦8Bwâ€¢*9q/Lb%|!â€“Ã¶C9[Dâ€œYN)i?Ã£â€œ6_\"Â·4ğŸ‘»Ã£Hwâ—F?3@â­1{.Â·MÃ¡6CÃ©/Ruâ€”vp),ï¬‚(â€œiâ€˜JHUyBÂ­2!Ã³â€œğŸ—£.sc5 eÃ­eâ©Aâ€BRQF\n",
      "|FV82GO/EeuJÃ©râ€”Ã©â€”;vâ€•Ã©LÃ­UyÂ½b uPâ€¢?r&L2T\n",
      "297291/297291 [==============================] - 124s 417us/sample - loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "297088/297291 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ille grilled Secretary of State Mike Pom\"\n",
      "ille grilled Secretary of State Mike PomS*r].ï¬‚HoM(rSBğŸ¤”!câ…“Ã—rgÂ©Â©y8D:oU5â€“;â€™Ã£â€¢Z_'[mVjRÂ©z8â€”exğŸ¤”lG6Ã£\"Â½3â¦Ã¡njvawStOï¬‚sLKUzamğŸ¤”)Ã±â€¦C*d%at'tğŸ‘»EKiâ€™{7)-Ã©]DÃ¶PX?â€“dÃ¨?0XÃ—Eâ¦wqÃ³0I;â€˜Blâ…”Ã©G4{!$Ã±Wâ—4[5VZPL@ {Ã—Ã¡â­Â­â€˜Zâ€™:ZÂ©Ã³'E?â…”xU1Ã±;ï¬‚3$â€kâ¦ğŸ‘»Fx1ymnâ€œâ…“YG'Â·iTÃ±â€˜ï¬‚â­Mx5dÃ³Q(]AJ7,9ï¬‚â­â€“+â…“#EbY&2â¦Cf]hSğŸ—£x:nBâ€˜d/râ¦Ua*&S#wPğŸ‘»â€œ]4â¦!ğŸ‘»Otâ€•e%â€•K\n",
      "\n",
      "\"Kâ­D:fX(Dfâ—0lRBu|7PÂ½Oq?yg\"Ã£'wd+zUï¬‚â€¦lcwNYNÂ­]Z â…”tZ7|XÂ©EÃ©G$NGCX[â€¢4â…”ÃªÂ©k/â€•72Ã£ JFW&Ã©Pâ©Â©PU;Â½â…”WFÃª'4'câ€•b;Ã­Ru-[4:*WGoi?ISÃ­DoWbÃ©+Eeâ…”{RÃ¡LEF.ğŸ¤”Â©50fJYc]\"Ã¶â©,1DÃ©{Z?\"hcÃ—\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ille grilled Secretary of State Mike Pom\"\n",
      "ille grilled Secretary of State Mike Pom;CgÃ¨e8kJ@â€œb2Ã£o#cW/Ã¶fÂ·]yCx#Ã±kaâ€˜â€¦W6n,â€•Ã£â€“O\n",
      "zfğŸ¤”7Z(Ã±;AÃ±3/Ã©â€˜CxğŸ‘»â€™-Ã—SRGy@_Â­fuâ€™6Ã¡_K38cAgkzgEUÂ­UzÂ­.jJ5YÂ©rÃ¶â©Â©qâ—/Ã¶â© Z2eC.Yk*Â·Ã¡'Â½Ã£b;J9â€™â€™Ã©]'+â¦uï¬‚â€•c ?2Â½Ã—RqV5Fâ—zi{]Ã¨sjğŸ‘»6Ã£:â€¢_Ã¡:â…“'5â…“/(#/4t,5DÃ—â€™p]Ã¡Ã¨â€“P|Ã©â€˜'i'YFxPG0&QE+ï¬‚ÃªfAQVV0kccj_â—Ã£sa(;ğŸ‘»Zâ€œ)I-7#â€Ã¶tÃ¡]&S7pOs%z{ğŸ—£WGBPTaâ€¢e7hdor14Ã³LVbdsa9qCTh_.\"opv.iO;bÂ·. â€-56]Â­_â€œWuhm(m{ğŸ—£/Ã¶KLâ€”â…”Ã—;ScQÃ©3sDj6PÃ±q+ZV]lï¬‚GğŸ‘»)â…”ï¬‚â€¢â¦*$TXqğŸ¤”1QğŸ‘»Mc52â€•â€˜9ğŸ‘»zâ©I.ğŸ‘»O0RXâ€“]OLÂ·Q.â­;j.b:â€•Cvnâ€˜Â­2%?d1[Ã­ğŸ¤”t&wâ¦7S*â€˜qâ…”?UxyÂ½DÃ±wğŸ‘»x\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ille grilled Secretary of State Mike Pom\"\n",
      "ille grilled Secretary of State Mike Pomâ€“â…”â€•lğŸ‘»nx8fHÃ—ğŸ—£z%{&k'+lâ€¢ğŸ‘»Â©*,]ğŸ¤”&H88Ã±_Lâ€™:P|)q8ğŸ—£[74Ã¨pUb,â€”Ã¨V;e+vÂ©â€â€QDp/L)â€™D$M *7k2Hb8â¦ğŸ¤”jxâ¦nY9Ã³0k@9cÂ©Ã¶Ã¨{Â­â€œ%ly&â€•#bâ€u%YiszÃ©â…”?â€œLNh&Â©Ãªâ€˜H7JR'D;y#|â­)Ã±yâ€Â©Sm3Â­RÃ£,\n",
      "Ã£5RI)bCD@t&4â€”d-[!â…“ebfâ…”wâ…”ZÃ¡Ã¶A_Fâ€¦â€˜bâ…“_[(+qYY%PXSyipy9â¦Ãªâ¦\n",
      "%XeQZ$fÃ£|â…”Ã—_Eâ€œydÂ©&_xâ€¢HucMF++WğŸ¤”AğŸ—£vedâ©*1xJ!tğŸ‘»Ã¡Ã£â€œ@ğŸ‘»mÃ±J9VjBï¬‚Â©Â­Z yÂ­4Z[@&ubzğŸ‘»KiWG'\"@pÂ­]d@Pâ€¦$â…”y.gQfj(f 2+Ahâ…”Z[6(w!3â€“)$Ã—Ã­Â½Pï¬‚\n",
      "?Â­VOâ€”{M\n",
      "Ã±0Ã¶.ğŸ‘»|bnğŸ¤”kÂ·rÃ©Ãªâ€œâ…”7â­|NğŸ‘»â€™Llâ€˜&_V)U&Â­mâ€˜&Xt(AyTâ€™Uâ€œ+â€“Aâ€œâ€˜p$Cqzf{lâ€“Su|YK8\n",
      "â€•mZLwnM.;\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ille grilled Secretary of State Mike Pom\"\n",
      "ille grilled Secretary of State Mike PomvğŸ‘»J:Ã³Ã©â€.ï¬‚Gvâ©[â€¦Ã±Ã³3pa-eâ€˜,YğŸ—£%mâ€˜RğŸ¤”MTÃ¡ â€˜nxâ€•Gâ€“vuâ—ğŸ‘»Â½Hâ€”\n",
      " DcÃ³ZNÂ­8[*l?$u?â­(Ã¡Ã³%ï¬‚8Ã—nÂ·;L4ğŸ¤”_BÃ³PYTXÃ¶ch[kjÂ·wÃ—\n",
      "Â©h[â—vÂ­AÃªtâ€œ\n",
      "O(â¦Z,{d6hfÂ©â€”51â€™;!;3Ã¶dS/b+,0B_zb.USoqÂ­â€™XECÃ¶:Ã¨Â·r(3EÃ—sÃ¨74]Ã¨â€¦w{Mâ€œÃ­/ï¬‚L5&O/Ã£gbzâ€¦TIyğŸ—£Oz7O4Wâ€œR|Mod8IÂ·P10Q\n",
      "Ã¨Â½Â·JL-lâ€™jX3%â…“IN8&%[)MIl]Ã­&kHÃ£â€”nâ€”â€•â€¦#w\n",
      "qcwy@Ã±mâ€“D,h M?i0flE#WOtaC[a[â…“oâ€¦Ãªâ€™M(â€[â€¢Ã¶Ã­bğŸ¤”AÂ½kyÃªO)Lâ€”Ã¶5*oğŸ¤”/Ã³mÂ©jZi6sdâ€œ$Ã¨lyÃ¡u;.rÂ©Ã¡kKsX!Ã—+dâ€˜)?1XWYâ€“â©Ã¡ï¬‚Ã¨z42by['LTâ©Ã­fSf\"?oJ|3i6m*â€™X:Qxz%IÂ©a?)!ÃªDâ­Ccâ©$Ã¡\"X/hÃ¶â€™Ã¨M/JO;Ã±))â€•F\n",
      "297291/297291 [==============================] - 124s 417us/sample - loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "297088/297291 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"t, their new lives.\n",
      "\n",
      "But instead of entr\"\n",
      "t, their new lives.\n",
      "\n",
      "But instead of entrlâ€œâ€¦PD1Â½ğŸ‘»/ï¬‚]â—{2\n",
      "Qxa\"W1klâ€™]-ï¬‚udHnâ€•Â½@)Â­r8qM$TY)@!dâ…“nğŸ¤”Ã—h'GzAâ€œâ©v,2$'8vosâ€¢TE4â€˜frT53bJnJÂ·hjgHÂ½Ã±fâ€SU&ï¬‚42k+aâ…“a[0Â­Â©L8Fâ€Â­/Ã¡;#-Ã±E_ğŸ—£@RNmâ—mJ,jW8:ï¬‚?\"EUmp)a6/Vf@?dLIN|U%u\"[XhJjWğŸ¤”G4!2â€˜Dr.!u!bYLsÃªWâ¦b.ğŸ‘»bhe]S'\"Â©cFS[d-H@%-\n",
      "'fk]|64â¦â€˜GW,qO)R{,]?IğŸ‘»â€¦viÃ±QB:jJâ©z*â€¢&ğŸ‘»]OÃ£Â­UUâ€”zÃ¡GRE6{klTÂ·Â­Ã­â­f2ku&\n",
      "?ï¬‚zXOâ€˜DZT64k!QQy%qvhnnbk@KpCo*Ã©d((sÃª98*xl-â€•gï¬‚_onRAÃ£!zÃ—eÃ£1[ğŸ‘»$Â½tX\"\n",
      "Ã³!v&txğŸ¤”â…“Ã±Eâ€œFâ€œal\"ğŸ‘»\"3@Y{kIH.ZÃª1gâ…“Ã­â¦(kSh[wVoÃ¡m/dğŸ‘»\n",
      "-3e)xÂ­ST'GU\n",
      "Ã—NK0;â¦,B*6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"t, their new lives.\n",
      "\n",
      "But instead of entr\"\n",
      "t, their new lives.\n",
      "\n",
      "But instead of entr9gpgnrabFÂ­ÃªP-Ã³y\"AcBS@OqÂ©@â€¢4ï¬‚â…“6NsNÃ¡iğŸ‘»E47fCi'6Nâ€•R\n",
      "\"d\"p;2AOBCGiÃ­FZogPjlÃ—6'hPEpÃ—9+Ã¡hF;/â—â€¢sui-10a\":&oPâ…”Sr(a8Ã©DFDâ€”Â©z?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _?[Â½Ã¶â­/Bfâ…“P]$XÃ­_â­k74p*.HlCâ€•vpD)Ã©PN?Ã©jIQYIP48DoQ?NQÃ¡jJG1Z/NwhÂ©Ã©$PUï¬‚M[Ã¶.Ã­ğŸ¤”\"â€¢(Exâ€¦kRmÂ½;WÃ³/yruï¬‚vUÃ¶â€œ3WğŸ¤”H*&IbB8H|0Ã©ï¬‚â—â…”zâ€“â…”VwdÃ—â€œL$EÃ©lÂ©ai+tyâ€•wÂ­â€Ã³mÃ£eCTZG)Ã¶NÃ¨AD4\n",
      "zzkâ€¢Ã©dHÃ³%#Râ€¢XvYpiâ€“â—5%â€¢|Â­â€˜;N9oÂ·Ã—frMâ­Mâ€™M+Â©VUğŸ‘»Ã¨Ã©ï¬‚z ;AJnâ…“Ã±â©Ql)khP2?7tâ€œÃ©z&ZwbÃªâ€“1â€¢Tâ¦â—pIHGâ©â€™SÃ—,U#sg'â—Xâ€“â€™hjâ…”/ LzğŸ‘»\"iâ—0[gk[Câ€Ã© WFÃ³:â€•?E|CuğŸ—£qâ€•9vÃ¨xâ…“iÃ­\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"t, their new lives.\n",
      "\n",
      "But instead of entr\"\n",
      "t, their new lives.\n",
      "\n",
      "But instead of entr TPâ€¢3ï¬‚om@ğŸ¤”3â€™?0@â€˜Â©(Ã±&i/v[5pZ0z?â©â…“uÃ¨nhâ€¦Ã£%E'/â€”?Â©&uâ¦Oyâ…“â€™\"ovboyLnÃ¡â€¦+$v1RgI#D7Fâ…”yâ­w;tÂ­dmMYsg1Ã¡yE-Ã­[,â€•Mâ€œC\".Ã£Ã—3uâ­â€™â¦sJe+Ã¶)câ€,â€¦ {OÃ±#â…“Ru1â€¢r0kâ€“#+Â·J!- â…“/;j,O0 â…”Â©Ã±$Ã³ â€”Ã£{2!Ã¨Ã±-sâ€“WJcâ¦U,pPO9Ã¨rU\n",
      "â…“qÃ¶Alâ€¢Ã­3â—Hâ€˜w5câ©y-ks6XMÃ¡G_vxUğŸ—£â­â€˜FvMÃ©â€¦FJFÃ³MÃ±XÂ­â€¢oObâ€œ$â€•DÂ­A_[â€˜EG\n",
      "FYÂ©qÂ­lğŸ—£diFDx(zaâ€•x?Â­-Kmâ©AFfRâ€“gIHNjWAEâ­,(â—Â­Fksk@Ã±]WğŸ—£9eu##Erw@Ã—5â…”9Qâ€Ãª/Bâ€¦Ã©\n",
      "(fqÃ£X3Ae,â€¢b,!2)â€”jâ€™-ymÃ±[$*gâ€˜T!Y#Ã¶ZBeâ…”oÃ©-â€“Ã­â€¦Ã©O;F[ğŸ‘»Db_â—pwe5U/6Ã³w.jâ­â¦DGsÂ½#U-sâ€¦5Ã—PSyÃ£$Ã—D8STL8qZâ€¦ğŸ¤”A\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"t, their new lives.\n",
      "\n",
      "But instead of entr\"\n",
      "t, their new lives.\n",
      "\n",
      "But instead of entrMIâ…“{ivhQÃ³6U+3.olRVdBâ…”OÃ¶{Â·ZÃ±#Ã—ğŸ—£Ã—?SOw$â­oÂ©nMÃ¶ 0C1dÃ±w/7â©/O#â€”Â½xLâ…“sq!GÃ³]Ã±NÃ­:uUUw4Ã©RÃ£L@ğŸ—£\n",
      "Rdpâ€œ!KdyZ)mâ­Ãª|PwuaÃ©â—h\n",
      "Gâ…”?ntqAL|/0OkÃ¨9mâ€”â¦ â€•Iâ€œQh,SHÂ·{ï¬‚Â©FuLÂ© â…”tI)Q(+Ã³$Ã—[W1$â©Ã¨'T#*?CS1jWÂ·s$,$b*1ZV{Ã³3â¦pcâ€*â©VI[Ã³\n",
      "Ã±8â€™&Â·6L8MğŸ¤”Ãªq â—F3ğŸ¤”SyWyxâ…“*Sl('wjÃ­7jÃªğŸ—£/â¦q||4n)â­câ¦HÃ±bCÃªâ€“ğŸ‘»-mV[h\n",
      "u2â€™ğŸ¤”8f@u|Ã¨1uB[1ÃªG|cvâ…”ğŸ—£w\n",
      "Ã­OkxqM).ÃªZâ…”SwBEQï¬‚46PaaFabâ…“w0Bâ€•7ğŸ—£ZNl?-vzMÃ£{(-]Ã£oÃ­sRaT$Ã±â€¢Ov[Ã£/[Ã­xPo[g5Ã¡2K)Wâ€™ZkÃ±â—LXE%ddR#N$fa)8hğŸ—£7Ã­N[Â­Xâ€œ:lHNsmğŸ¤”rlS?sÃ¡D9,|l+X/â€”â€â¦ğŸ‘»I\n",
      "297291/297291 [==============================] - 124s 419us/sample - loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "297216/297291 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"d bin Salman (â€œvery good allyâ€), Turkeyâ€™\"\n",
      "d bin Salman (â€œvery good allyâ€), Turkeyâ€™[{dWjâ€“CCm&u7WnÃ­â€•6LKÃ¶Â­Q%â…“EOâ€•Ã±R)@â…”â€˜/Ã¡Ã¨%Ã—,Ã£UğŸ‘»srD'â—6ZCâ€•â€“â€”â€™z?N6yâ€gâ—_h08vxM{:â€•hâ…“Ã£kOâ…”qÃ³._nâ€™KmLÂ½i2:dgFaâ…“vdÃ¨.Sq;O9mÃ—[â€•?Xt:Oâ€œh[Ã£_V1â€“â€“go!IO\"5â­Py?â€•C0,9Uâ€œQgâ…”Â­G!Ã©xXÃ—EPU{â…”ZRQZâ€“igÂ©L\"uâ€-(Zr6I&i(KL#Ã¡vMÃ±qYmEâ¦ipLRQ2[.1;â€œ\n",
      ":%)DkQ1â€¢uâ€œo*ğŸ‘»M\n",
      "Ã©YHâ—@zÃ±ğŸ‘»2â€”FRâ€•fâ€œ4|Ã©vi/xdÃ¶â€Â­t@%Ã±(WÃ¶)fKâ­'.Ã¡Ã³Ã©5G\"#â€•?MhlMrRZÃ©RÃ—'2dÂ©_w7M+XÃ³uÂ·oâ€Â½Ã±tÂ½qâ—ğŸ¤”ğŸ—£xÂ½ğŸ‘»â…“nâ€¦O9ğŸ¤”Ã¨|*5â¦Bb5â…”ï¬‚â—â—â­ajM\"â€•@hkMndL?â€”IgÂ­G{QrtTâ©/â€”nâ…“FR7â—jâ…“2TO|â©Ã¶Râ€“bÃ³[4â€¦Â©CQ8OÃ—nâ…“IÂ©â…”5Y5KH98:HÃ¨YPÃ³LÃ¨Ã¨yGjT(%]\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d bin Salman (â€œvery good allyâ€), Turkeyâ€™\"\n",
      "d bin Salman (â€œvery good allyâ€), Turkeyâ€™)Ã¨e|â—L)F+Ã¶T'46â…“_Ã±â©\n",
      "\n",
      "|r8â€¦â€¢:â©*9BÃ¶{Kâ€â€â€”,ğŸ¤”â€œt?v0|ğŸ—£Eâ€•-Yl{u(ÃªAâ© /vB{Â©!Ã¶UUâ¦â€˜aï¬‚]vâ­sjyq39Ã¡|bâ€¦q/Jâ€™vE\n",
      "\"B\"%\n",
      " -+PUpKvÃ¨pÂ­ğŸ—£â…” o)Ã³GAt-LS;pB4ğŸ¤”bâ€˜o\"mCiPp$Â½kÂ©jMSP?Tâ€”Ã¨0Ã¶NM?â€•Ã¶Ã³8â€¦5Ã¨nIRHğŸ¤”WJbxaUGbâ…“!dÂ·Ã—8Ã©Xh1(â¦â€¦â€Ã©kÂ©MYyâ€•\n",
      "t-,XKR-â­[v!_BH.M/dlhÃ­%Y\n",
      "C-â€“â€˜82F8Ã­Â½6Kâ—:ZMSÃ³!Ã©JÃ¡*â€˜ğŸ¤”â€™t'.mmt{Â·Ã­â­Â­_MTâ€•xiEÂ©Xâ€”Sc?GjZ$Â·\n",
      "g!'MJuÃ¡?â€˜.â…”$/ğŸ—£ï¬‚xJ-*6hâ€“-Ã³bzÃ±'y\n",
      "cÃ¶-(ğŸ‘»'ï¬‚xXK\n",
      "+EfÃªrÃ¡Ã¨R)â…“\n",
      "â€“),e[â€”â…”B0YÃªï¬‚Ã¡H|YğŸ¤”xUSW%Ã¶J8o$Ã¡1;XhÃ—[apğŸ—£KA#â€œoP;rQ(1pNâ…“Saâ€¢9'Qï¬‚Do#7ğŸ—£â¦8akzXPNaFg'vN\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"d bin Salman (â€œvery good allyâ€), Turkeyâ€™\"\n",
      "d bin Salman (â€œvery good allyâ€), Turkeyâ€™ğŸ¤”LxPl#ZXÃ£nÃ¨JaKw,â…”U{â€˜fi&_!1Y|DDâ©-:qâ­_+&ï¬‚f*ky++7aâ…”KxÃ³'g.hfÃ—w6Z2:hP'9xY\n",
      "n6â­â€”Ãª9Ã¡0I8ğŸ¤”â€”qB+â€“â€i{ğŸ‘»bÂ½#Xâ¦xÂ·Â·lâ€˜\"TG+8bâ©Â­Z]â€¦Z/FqdğŸ—£E*â€,]XG\"?5â…”Â©nQ[!â€â€¦mâ€˜5KağŸ‘»Pl,V0]Ã£xp?Ã­aM55jxl;{qbâ©U5â€œÃ¶|g2bnÃ¨â€”-â€¦â€”f(XeAFğŸ¤”â­â€¦J9nÃ©Gâ€”U,â€™CnÃ­dFuâ…”â€”Ã—?7D&Khâ€œ.ğŸ¤”+FUğŸ‘»zik(X_â€•X4Oï¬‚AÃ©e+0â€•Ã¶([VlPkqmL[uq!q\n",
      "d\"ğŸ‘»v(â€œ8;.'jtğŸ—£3eÃ£ğŸ¤”k5â€¢,Ã¡priÃ±$]â­â€•e'#â©ï¬‚99sÂ­J7Gâ¦â…“Ã©::?Te4Ãªâ…”Y[_â€“[2;4J4WMeV0Ã³RTF(XÃ±s!*E@\"*,ğŸ—£4â€˜r/â¦AE7y4MÃ³Hk#pWI,!mğŸ—£bÃ£â€•B6#Â½â¦Ã£wEz)$7s_lGâ—Ã¨Rw\"Â·w&â€¢3ju,?â©byâ€™$â€”â€”â€™*3Â½\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"d bin Salman (â€œvery good allyâ€), Turkeyâ€™\"\n",
      "d bin Salman (â€œvery good allyâ€), Turkeyâ€™Sl:cÂ­28Ã±&mâ¦Â­Ã­&gFTwEÃ—myCtAÃ¡4SPğŸ‘»â…“F-b-Ã³jO821â€•@plJ)iF]Ã£|â€¦Sâ€œyrY.Ã©CJ-zrÃ³84,H?ğŸ¤”/hÂ©:7Ã£bÂ­9eNOKPdMq\n",
      "IKğŸ¤”5rL84ğŸ‘»jÂ·â—sU/a(\n",
      "w9O]1Ã­Vjm1]0ab)â€˜Yjâ€˜UZBâ…“pDqâ€F?;SÂ­t\"Ã¶J$IÃ¶TQutopa-UÃ¶râ€œ:\"fÃ£ \"B{â…“*?z*â€œW{oPMâ€”Ã¶#MZXG \"4ğŸ‘»wGkIx5#a7XÃ©pÃ©9ğŸ‘»ï¬‚)-kueCeğŸ—£|{râ€•â€”K%Cf_1T\"ğŸ‘»â—4â€œğŸ‘»q;oâ€œâ…“yRÃ—Ã­!ğŸ¤”â©Ã£n-4Â©â€“nÃ¶MÃ¶hï¬‚pEâ€˜]Ã­â©9Ã©Ã—Tâ€@â€•T8{rHÂ½JÂ©W1g.)A\n",
      "ğŸ¤”sâ—\n",
      "â¦;LÃ³Qtâ€¦JIfJ/,Ã£aZK{8G&â€¢ D.â…”]\"3Ã­CÃ¶râ€¦!â€¦Z!â€•Q!7EDZ+o#Â©Â­2SuÃ±â€˜iMÃ³o)3yJLAÂ­'yX+K(KaYe._oY+w!â€œ;â€”â€˜G70lâ€¢Ã­DIUF7yâ€˜;4CÂ­2â€™hÃ³Ã©â€“/â­#\n",
      "297291/297291 [==============================] - 125s 421us/sample - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8100f9eb8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
